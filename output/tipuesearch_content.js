var tipuesearch = {"pages":[{"title":"La puce TPM, quelle est son utilité ?","text":"Il y a moins d'un mois Microsoft annonçait officiellement Windows 11. Cette nouvelle version à fait débat, et pour cause, beaucoup (trop) d'appareils sont incompatibles avec cette version de Windows, une des raisons avancées par Microsoft est le support manquant de TPM 2.0. Mais au fond, Qu'est ce que TPM et quels sont les changements apporté par la deuxième version de TPM. TPM est l'acronyme de \"Trusted Platform Module\", c'est une puce qui permet de faire des opérations cryptographiques, ou de garder des secrets. Cette puce est principalement faite pour générer des clés RSA – RSA est un algorithme de cryptographie asymétrique – stocker ces clés et gérer l'accès à ces dites clés. Cette puce est aussi utilisée pour Secure Boot . Une puce TPM possède une clé RSA qui permet de l'authentifier, cette clé ne peut en théorie pas sortir de la puce. Un des usages principaux de TPM est de stocker différents secrets, pour par exemple chiffrer un disque avec une technologie comme BitLocker sous Windows, ou Luks sous Linux. La sécurité du stockage de la clé pourrait poser question, comment s'assurer qu'un autre système ne puisse pas avoir accès a la clé de déchiffrement ? Afin d'améliorer la sécurité de cette puce, on peut configurer un PIN à entrer pour accéder à la clé de déchiffrement. Si la clé n'est pas protégée par un PIN, la puce laissera quand même l'accès uniquement au système qui a crée la clé, même si dans certains cas particulier la vérification ne se fait pas correctement. Comme faille de sécurité dans TPM on peut notamment citer TPM-FAIL qui permet simplement d'extraire la clé privée. Un autre problème de sécurité que présente TPM est qu'avec un accès physique il est possible d'espionner ce que la puce fait et donc d'en extraire des données confidentielles, si vous souhaitez en savoir plus, la page Wikipedia sur TPM cite d'autres failles de sécurité : https://en.wikipedia.org/wiki/Trusted_Platform_Module#Attacks . Un autre problème de TPM qui est très répandu c'est le vecteur d'attaque physique, en observant directement sur les bus de la puce avec du matériel spécifique il est possible d'extraire les clés de la puce, ce type d'attaque se nomme cold boot atttack . La puce TPM est divisée en plusieurs partie qu'on nomme des Platform configuration Registers qui ont plusieurs utilité, comme le stockage de clé, firmware etc. TPM a connu des évolutions, je vais me concentrer ici seulement sur la version 1.2 et 2 de TPM. Une des avancées majeure est l'implémentation des courbes elliptiques sur la version 2, les algorithmes de chiffrement à courbe elliptique sont des algorithmes de cryptographie asymétrique, concurrents à RSA notamment, qui au lieu d'utiliser les nombres premiers utilisent des courbes elliptiques, l'avantage comparé à RSA c'est leur résistance supposée aux ordinateurs quantiques. Une autre avancée est le support de SHA256 qui est bien plus résistant que SHA1 à différent type d'attaque. À mon avis, le fait pour Windows 11 de forcer TPM est relativement inutile, en effet BitLocker n'est pas activé par défaut, et Secure Boot ne dépends pas forcément de TPM. Le mieux serait de recommander sans pour autant forcer. TPM reste très intéressant pour éviter de taper un mot de passe au boot, qui en plus de prendre du temps peut être vu par un attaquant, et permettre de vérifier l'intégrité du démarrage en séparant la gestion des clés du bios (l'avantage est que pour changer le jeu de clés publiques il faut effacer la clé de déchiffrement). Un des soucis les plus important de TPM reste que la plupart des implémentations ne sont pas libres, une backdoor pourrait donc y être inséré par le constructeur. Une alternative à TPM peut être des puces plus spécifique comme la puce titan de google, ou T2, mais ces deux puces restent malheureusement propriétaires.","tags":"misc","url":"https://ilearned.eu.org/tpm.html","loc":"https://ilearned.eu.org/tpm.html"},{"title":"Comment faire une autorité de certification (CA) SSH ?","text":"SSH est un protocole très répandu sur internet, il est utilisé par des millions d'entreprises et particuliers chaque jour, mais bien souvent de façon peu sécurisée. Vous connaissez peut-être les clés SSH qui permettent une meilleure sécurité que les mots de passe, mais ces clés posent un problème, et notamment en entreprise, imaginez une entreprise avec 500 ingénieurs, il faudrait, sur chaque serveur SSH, mettre les 500 clés publiques des 500 ingénieurs ! Pour remédier à cela il existe une solution que nous allons étudier dans cet article, les autorités de certification SSH. La théorie Le système de certificats de SSH est relativement similaire à celui de TLS (x509), une première paire de clés publiques/privées est générée, elle servira d' autorité de certification , le clé privée de cette autorité de certification doit bien évidemment rester ultra confidentielle. On va ensuite générer une autre paire de clé sur chaque client. On pourra ensuite, avec la clé privée de notre autorité de certification, signer la publique des clients afin de générer un certificat. Ainsi, n'importe quel certificat signé par notre autorité de certification peut être considérée comme \"de confiance\". Signer les clés hôte Lors de la première connexion à un serveur SSH, le serveur envoie sa clé publique (appelée clé hôte) au client et le client doit approuver, ou non, l'authenticité de la clé envoyée par le serveur, c'est le fameux message The authenticity of host 'XXXXX' can ' t be established. ED25519 key fingerprint is SHA256:JxfJl38mBVY2jX0h/LWDuB1OtgYfgLBr3nJw/lw5GFE. This key is not known by any other names Are you sure you want to continue connecting ( yes/no/ [ fingerprint ]) ? Nous avons tous pour (mauvaise) habitude de simplement entrer yes sans se poser plus de questions, mais cette habitude est très dangereuse, un attaquant pourrait usurper le serveur SSH auquel nous essayons de nous connecter ! Pour remédier à cela il existe plusieurs solutions comme SSHFP (qui est relativement similaire à TLSA , mais avec SSH) ou les autorités de certification (CA) c'est ce que nous allons détailler ici. La première étape est donc de créer une paire de clés pour notre autorité de certification avec la commande ssh - keygen - a 1000 - t ed25519 - f / etc / ssh / ca / id_ed25519 - C \"contact+ca@eban.bzh\" L'option -a indique le nombre de tours KDF (fonction de dérivation de la clé), plus ce nombre est élevé, plus la vérification du mot de passe sera lente, mais plus la clé sera résistante au bruteforce. -t indique l'algorithme à utiliser pour la clé, ici c'est ed25519, l'algorithme de chiffrement le plus sécurisé à ce jour supporté par SSH. Une fois cette première paire de clé créée, nous allons pouvoir l'utiliser pour signer les clés hôtes publiques de nos serveurs SSH, la première étape est donc d'aller cherche ces clés hôtes, elles sont, sur chaque serveur SSH, dans le répertoire /etc/ssh, ici je ne génèrerait qu'un certificat en ed25519 mais la même démarche est possible avec n'importe quel algorithme supporté par OpenSSH. La clé publique hôte est donc disponible sous le chemin /etc/ssh/ssh_host_ed25519_key.pub copions-là dans le répertoire /etc/ssh/ca de la machine sur laquelle nous avons généré l'autorité de certification. On peut ensuite lancer la commande ssh-keygen -h -s /etc/ssh/ca/id_ed25519 -n pi01,pi01.infra.eban.bzh -I pi01 -V +3650d ssh_host_ed25519_key.pub L'option -n correspond aux principals , dans le cas d'une clé hôte, elle doit correspondre aux différents noms de domaine auxquelles la clé pourrait être associée. -I correspond à l' ID , un identifiant unique attribué à la clé, c'est simplement son \"nom\". Une fois la clé publique signée, il ne nous reste plus qu'à copier le certificat qui aura été généré dans le répertoire /etc/ssh/ca/ssh_host_ed25519_key-cert.pub sur le serveur SSH (ici nous le mettrons à l'emplacement /etc/ssh/ssh_host_ed25519_key-cert.pub ) et à ajouter la ligne suivante à la fin du fichier /etc/sshd_config . HostCertificate /etc/ssh/ssh_host_ed25519_key-cert.pub On redémarre ensuite le démon ssh avec la commande systemctl restart sshd . Dernière étape, on va indiquer à tous les clients SSH de faire confiance aux certificats hôtes signés par notre autorité de certification en utilisant la commande echo \"@cert-authority * $( cat /etc/ssh/ca/id_ed25519.pub ) \" >> ~/.ssh/known_hosts Et voilà ! Notre autorité de certification est maintenant configurée sur le serveur SSH. Signer les clés clients La procédure pour signer les clés des clients est relativement similaire, après avoir généré une paire de clés pour l'autorité de certification (on gardera la même que celle générée dans la partie précédente), on lance la commande ssh - keygen - s / etc / ssh / ca / id_ed25519 - n pi - I pc01 @eban . bzh - V + 30 d - z 1 / home / USERNAME / . ssh / id_ed25519 . pub N'oubliez pas de changer USERNAME par votre nom d'utilisateur. Si vous obtenez une erreur, c'est probablement que n'avez pas déjà une paire de clé SSH en ed25519 vous pouvez en générer une avec la commande ssh-keygen -t ed25519 Une fois la paire de clé générée, vous pouvez relancer la première commande. Ici l'option -n correspond au⋅x nom ⋅s d'utilisateur distant (= sur le serveur SSH) pour lesquels vous souhaitez autoriser que cette clé soit valide, cette clé ne sera donc valide que pour le nom d'utilisateur distant pi . -z correspond au serial de ce certificat, c'est un nombre que vous devrez incrémenter si vous régénérez la clé après la durée d'expiration (ici mise à 30 jours). Une fois cela fait, il ne nous reste plus qu'à copier la clé publique de notre autorité de certification (contenue dans /etc/ssh/ca/id_ed25519.pub ) sur notre serveur SSH, ici nous la mettrons dans le fichier /etc/ssh/ca.pub et à ajouter la ligne TrustedUserCAKeys /etc/ssh/ca.pub à la fin du fichier /etc/ssh/sshd_config . On termine par redémarrer le service SSH, sudo systemctl restart sshd . Nous avons maintenant mit en place notre autorité de certification ! On peut simplement la tester en se connectant via SSH au serveur, vous ne devriez pouvoir vous connecter sans mot de passe et n'avoir aucune demande de validation de la clé publique de la machine hôte. J'espère que cet article vous aura été utile, si vous avez des questions n'hésitez pas à nous les poser en commentaire ou sur Twitter .","tags":"misc","url":"https://ilearned.eu.org/ca-ssh.html","loc":"https://ilearned.eu.org/ca-ssh.html"},{"title":"Sécuriser votre système d'exploitation grâce aux MAC","text":"Un reproche souvent fait à Linux est sa gestion des droits souvent trop permissive. Il y a bien sûr une raison historique, à la naissance des différents systèmes d'exploitation que l'on connait aujourd'hui la sécurité n'était pas la préoccupation principale. Le but de base n'était pas non plus de compliquer la tâche des utilisateurs (la sécurité se fait toujours au prix de complexité supplémentaire). Le problème de cette philosophie de départ est qu'il faut repenser la sécurité avec une base trop ouverte. Sous Linux tout est fichier, les périphériques physiques ont par exemple, un fichier attribué dans /dev . La sécurité d'accès pour les fichiers se base sur les permission de chaque fichier. Ce mécanisme montre vite des limites. Les autorisations sont très limitées, sous Linux ces autorisations sont divisées en 3, ce que l'utilisateur propriétaire peut faire, ce que le groupe propriétaire peut faire et ce que tout le monde est autorisé à faire. Chaque partie peut avoir 3 droits différents : R (read) : Lecture W (write) : Écriture X (Execute) : Exécution (dans le cadre d'un dossier c'est l'autorisation pour lister le contenu) On peut visualiser les permissions via la commande ls -l <dossier> : % ls -l total 0 - rwxr - xr - x 1 ramle ramle 0 Jul 19 17 : 05 executable - rw ------- 1 root root 0 Jul 19 17 : 05 root_only ls divise en 3 parties les permissions, celle de l'utilisateur, du groupe et de tout le monde : Le soucis de se baser uniquement sur les permissions des fichiers est le manque de contrôle, le schéma de sécurité des MAC permet de renforcer le tout en regardant beaucoup plus de facteur. Le concept est de regarder toutes le actions faites sur la machine, et de regarder l'action et l'autoriser ou non en fonction des règles d'accès. L'avantage de ce modèle par rapport à la sécurité historique de Linux (et UNIX par la même occasion) est d'être bien plus précis, par exemple autoriser à une application seulement certains ports et fichiers (fichier qui pourrait selon le système de fichier lui être autorisé). Sous Linux, il n'y a pas de base de framework de MAC, mais des modules dans le noyaux sont prévu pour qu'on y greffe un framework il y en a deux importants, Apparmor et SELinux. Les deux ont des fonctionnalités similaires, mais se différencient par un point important, Apparmor se base sur le chemin complet d'un fichier, là ou SELinux se base seulement sur le nom, cette différence est assez minime dans la plupart des cas, mais en fonction du framework utilisé, des méthodes de contournement se basant sur ces spécificités, par exemple en utilisant des liens virtuelles (symlink) ou renommant un fichier, une bonne politique d'accès évite cependant les contournements. Bien sûr, Linux n'est pas le seul système d'exploitation qui utilise des contrôles d'accès plus poussé qu'uniquement des permissions basiques, Windows fonctionne sur ce principe aussi tout comme MacOS et BSD avec l'intégration de TrustedBSD.","tags":"misc","url":"https://ilearned.eu.org/mac.html","loc":"https://ilearned.eu.org/mac.html"},{"title":"MQTT, comprendre le standard de la domotique","text":"Si vous vous êtes déjà intéressé⋅e à la domotique, vous avez sûrement entendu parler du protocole MQTT (Message Queuing Telemetry Transport), MQTT est un protocole très utilisé pour faire de l'automatisation notamment, nous allons entrer plus en profondeur dans le fonctionnement d'MQTT dans cet article à travers l'exemple d'une lampe connectée. MQTT fonctionne sur le principe de Topics dans lesquels les différents appareils peuvent publier ou recevoir des messages. La fonctionnement de ce protocole est relativement simple, le client commence par s'authentifier auprès du serveur, puis il peut recevoir et/ou envoyer des messages au serveur, appelé Broker , voici un exemple de trame réseau. On peut donc voir que ce protocole est très simple de fonctionnement, et ce n'est pas un hasard qu'il soit très utilisé en domotique, bien souvent les appareils en domotique sont tout petits et n'ont pas la capacité d'implémenter des protocoles très lourd. Vous pouvez voir ci-dessus un exemple très simple d'utilisation du protocole MQTT, un téléphone publie un message au broker MQTT sur le topic stat/phone quand le réveil sonne, une lampe connectée est abonnée au topic stat/phone , quand un message indiquant qu'une alarme vient de sonner lui parvient, elle s'allume et indique par un message sur le topic stat/lampe/POWER qu'elle est allumée. Ce scénario est très simple mais il montre à quel point MQTT est modulable et peut permettre une automatisation poussée. Si vous êtes intéressé⋅e par la domotique, sachez qu'il existe des petits modules appelés modules Sonoff qui permettent de rendre \"connecté\" n'importe quel appareil électrique (une lampe de chevet par exemple) et qui, une fois un firmware (système d'exploitation) spécial appelé Tasmota flashé permettent aussi de publier des messages sur un broker MQTT. Si vous n'êtes pas un aficionado de la ligne de commande, il existe des logiciels comme Node-RED ou Automate sur Android qui permettent de s'essayer à la domotique et l'automatisation facilement.","tags":"misc","url":"https://ilearned.eu.org/mqtt.html","loc":"https://ilearned.eu.org/mqtt.html"},{"title":"Vérifier l'intégrité d'un système d'exploitation grâce à Secure Boot.","text":"La sécurité d'un système dépends de beaucoup de facteur, un des facteurs important est de pouvoir vérifier l'intégrité du système démarré, en effet sans cette vérification un attaquant pourrait sans trop de difficultés modifier les fichiers de démarrage pour ajouter un malware. Cet article se concentrera sur les machines de bureaux. Pour bien comprendre comment peuvent être effectuées des attaques pendant le boot il est important de comprendre le fonctionnement du démarrage en mode BIOS, et son remplaçant l'UEFI. BIOS Le démarrage en BIOS s'appuie sur une table des partitions en MBR (master boot record), pour démarrer le bios va exécuter du code contenu dans la table des partitions, ce code s'occupe de passer la main au bootloader qui va s'occuper de lancer le système. Un problème assez flagrant apparait déjà, du code peut être directement inséré dans cette partie, aucune vérification n'est effectuée par le BIOS. Un attaquant pourrait aussi attaquer le bootloader qui ne peut pas être chiffré. Sous Linux (nous verrons le fonctionnement de Windows un peu plus loin) le bootloader le plus courant est grub, il insère dans le MBR de quoi charger son code complet qui est contenu dans /boot , la plupart des bootloader sous linux fonctionnent sur le même principe. Pour éviter une modification du système on pourrait chiffrer le partition root (aussi appelé Userland) et faire un /boot à part (le bootloader ne peut pas être chiffré), un problème se pose alors, l'initramfs et le kernel sont toujours en clair. Grub (et c'est à ma connaissance le seul) permet de déchiffrer le partition boot, pour garder l'initramfs et le kernel chiffré. Mais grub en lui même est toujours modifiable, même chose pour le code exécuté directement dans le MBR. En plus de ne pas être totalement sécurisé, avec cette méthodes la phrase de passe doit être tapée deux fois, une fois pour lire l'initramfs et une autre fois pour déchiffrer la partition root. (grub ne la retient pas). Une solution possible serait de signer les différents élément du boot, le problème est qu'en BIOS aucun mécanisme pour la vérification de signature existe. Avec un BIOS nous n'avons pas de possibilité de sécuriser entièrement un système Linux. Pour Windows, le concept est très proche, le BIOS va exécuter le code dans le MBR, ce code va enclencher le bootloader de Windows qui, depuis Windows Vista, est bootmgr, chiffrer son disque pose le même soucis que sous Linux, le bootloader restera en clair. UEFI Avec UEFI on se passe de MBR au profit de GPT qui apporte un certain nombre d'avantages. Le processus de boot ne se passe plus par un code exécutable dans la partie MBR, ce code est contenu dans une partition en FAT32 (ou FAT16), ce qui permet de ne plus être aussi limité en taille, la partie dédié au code de démarrage dans MBR n'est que de 446 bytes. UEFI apporte aussi une évolution majeure pour la sécurité : Secure Boot, c'est un moyen de vérifier l'intégrité via une signature du fichier EFI. Un fichier EFI est un exécutable lancé par l'UEFI, on pourrait le comparer aux ELF de Linux, ou aux exe de Windows. Lorsque qu'un pc avec Secure Boot démarre, il vérifie le binaire EFI, pour voir si la signature corresponds à une clé de \"confiance\" et si la signature n'est pas dans dans la liste des clés à refuser. L'UEFI se base sur des variables pour les clés, vous pouvez les voir depuis Linux via l'utilitaire \"efi-readvars\", ce qui sur ma machine donne : Variable PK, length 823 PK: List 0, type X509 Signature 0, size 795, owner 5b2a4205-8ee1-404d-a357-45629f968019 Subject: CN=Ramle PK Issuer: CN=Ramle PK Variable KEK, length 825 KEK: List 0, type X509 Signature 0, size 797, owner 5b2a4205-8ee1-404d-a357-45629f968019 Subject: CN=Ramle KEK Issuer: CN=Ramle KEK Variable db, length 823 db: List 0, type X509 Signature 0, size 795, owner 5b2a4205-8ee1-404d-a357-45629f968019 Subject: CN=Ramle DB Issuer: CN=Ramle DB Variable dbx has no entries Variable MokList has no entries Regardons de plus près chaque variable : PK : C'est la clé la plus haute dans la chaine de confiance, elle est là pour signer la clé KEK, une seule clé est possible dans cette variable. En général c'est le constructeur qui met sa clé, si vous voulez contrôler totalement la chaine de confiance il faudra donc la changer. KEK : Ces clé sont utilisées pour signer les clés qui iront dans DB ou DBX, souvent de base il y a 2 KEK, une pour Microsoft et une autre pour le Fabricant. DB : Ce sont les clés utilisées pour la vérifications des binaires EFI, souvent l'ordinateur vient avec les clés du constructeur, de Microsoft, Canonical (entreprise qui est derrière Ubuntu) et parfois d'autres entreprises. DBX : C'est la liste des clés qui ne sont plus de confiance. MOKList : C'est utilisé par un outil du nom de Shim, cet outil est là pour charger un autre bootloader qui ne serait pas signé avec les clés présentent dans DB, Shim va vérifier le bootloader via les clés dans la MOKList qui est géré par l'utilisateur, et non via l'UEFI directement. Ces variables sont bien sur modifiable sur la plupart des pc, ce qui permet de gérer sa propre PKI (public key infrastructure). Si on veut un réel contrôle il faut gérer soit même ses clés, sous Linux c'est possible sans trop de difficultés, FreeBSD et OpenBSD semblent supporter aussi (je n'ai pas eu l'occasion de tester) et sous Windows on peut soit utiliser les clés de Microsoft ou utiliser ses propres clés ce qui semble en théorie possible. J'espère que cette article vous aura plus, je pense prochainement faire un petit guide pour la gestion de Secure Boot sous Linux, je vous laisse donc surveiller les sorties 👀. On se retrouve après demain pour un article sur MQTT","tags":"misc","url":"https://ilearned.eu.org/secure_boot.html","loc":"https://ilearned.eu.org/secure_boot.html"},{"title":"Les version oubliées du protocole IP 🔎","text":"On connait tous IPv4 et IPv6 qui sont deux protocoles largement répandus (bien qu'un des deux ne le soit pas assez &#94;&#94;), mais on pourrait légitimement se demander s'il existe d'autres version du Protocole Internet, nous ferrons donc dans cet article un petit tour d'horizon des différentes itérations du protocole IP et de leurs spécificités. IPv1 2 et 3 − La genèse du protocole Internet Le premier document décrivant le fonctionnement d'IP est la RFC 675 publiée en 1974 mais présentée dès 1973 à l'International Network Working Group. Si vous parcourez cette RFC vous remarquerez qu'elle ne fait pas mention du protocole IP, mais de TCP, en effet à l'époque, TCP et IP n'étaient pas séparés et le principe de couches apporté notamment par le modèle TCP/IP, sortit en 1976, n'était pas encore d'actualité. Parler d'IPv1 est donc un abus de langage, le terme adapté serait plutôt TCP version 1. Ce protocole avait une particularité intéressante, il contenait quatre champs adresse dans son header, contre deux pour IPv6. Un pour le réseau de destination (et d'origine), rappelez vous, nous sommes en 1974 et à cette époque le réseau Internet comme nous le connaissons aujourd'hui n'existe pas, il existe donc différents réseaux concurrent, ce champ dans l'en-tête a pour but de spécifier sur quel réseau le paquet doit transiter. Ainsi, vous pouvez voir ci-dessous les différentes valeurs possibles pour ce champ et donc les principaux réseaux qui cohabitent à cette époque. 1010 = ARPANET 1011 = UCL 1100 = CYCLADES 1101 = NPL 1110 = CADC 1111 = EPSS Les troisième et quatrième champs sont destinés à accueillir les adresses TCP d'origine et de destination, ces adresses ne sont pas très détaillées dans la RFC, mais on sait qu'elles sont d'une longueur de 16 bits (65 536 adresses différentes), elles correspondent peu ou prou à ce qu'on appelle aujourd'hui \"adresses IP\". Cette première version de TCP est vraiment expérimentale, elle n'a pas été déployée à grande échelle comme l'ont été IPv4 et IPv6 Vient ensuite en 1977 la deuxième version de TCP (et donc par extension du protocole internet), cette version, publiée dans l' IEN 5 , apporte certaines améliorations dont notamment le passage à un \"Network Identifier\", ce qui était auparavant appelé réseau de destination/origine, codé sur 8 bits. Autre différence, les \"host identifier\", anciennement appelés adresses TCP , sont maintenant codés sur 24 bits, soit un total de 16 777 216 adresses. On peut aussi voir le début de la séparation entre TCP et IP dans ce schéma d'époque avec les parties \"TCP Header\" et \"Internet Header\". Séparation qui sera actée dans la version 3 de TCP, publiée en 1978, ce qui représente une avancée majeure dans l'évolution du protocole internet. IPv5 IPv5 n'a pas réellement existé, il s'agit en fait du Stream Protocol , abrégé ST-II, un protocole de couche 3 (comme IP), créé pour faciliter l'envoi de vidéo et d'audio par internet et qui avait dans le champ version la valeur 5. C'était donc une version modifiée d'IPv4 mais qui avait des adresses codées sur 32 bits, comme pour IPv4, qui ne répondait donc pas à la problématique principale posée par IPv4, le manque d'adresses. Ce protocole marque le début de VoIP (Voice over IP) mais il ne sera pas déployé à grande échelle, VoIP sera ensuite simplement déployé sur IPv4. IPv7, 8 et 9 − Le futur ? Ou pas… IPv7 est un protocole appelé TP/IX sortit en 1993, les adresses IP sont codées sur 64 bits (contre 128 avec IPv6), on ne détaillera pas plus ce protocole mais si vous souhaitez en savoir plus je vous invite à lire la RFC d'IPv7 qui est très compréhensible. IPv8 (mon petit préféré &#94;&#94;) appelé PIP et sortit en 1994 son fonctionnement repose en partie sur le système de DNS , chaque utilisateur du réseau a un PIP ID , un identifiant unique codé sur 64 bits, ainsi, peu importe d'où il se connecte sur le réseau, il est possible de l'identifier rien qu'avec son ID. PIP a donc été avant tout pensé pour faciliter les échanges entre appareils changeant d'adresse IP. On pourrait par exemple imaginer une connexion SSH utilisant uniquement le PIP ID pour s'authentifier et qui, même si un des deux composants de la connexion (le client ou le serveur) change d'adresse IP reste stable. Je parlais plus tôt du DNS, en effet, avec PIP le DNS est modifié pour renvoyer à la fois l(es) adresse(s) IP mais aussi le PIP ID . Ce système a néanmoins un problème majeur, le PIP ID permettrait de pister très facilement les utilisateurs. IPv9 enfin est un protocole très peu détaillé, il avait été annoncé en grande pompe par le gouvernement chinois, celui-ci se targuant du fait que cette version d'IP ait été adoptée dans les secteurs militaires et civils, mais depuis cet effet d'annonce aucune spécification technique n'a été publiée, seulement des bruits de couloir comme quoi les adresses seraient codées sur 256 bits et composées uniquement de caractères numériques (et non pas hexadécimaux comme c'est le cas d'IPv6).","tags":"misc","url":"https://ilearned.eu.org/versions-ip.html","loc":"https://ilearned.eu.org/versions-ip.html"},{"title":"Modèle de sécurité Windows","text":"Introduction \"Accès refusé\". S'il y a bien une erreur frustrante, c'est sûrement celle-ci. Sur Windows nous y sommes pourtant souvent confrontés, surtout dans une perspective attaquante. En revanche, peu de gens comprennent pourquoi cette erreur (ou d'autres) vient s'immiscer dans sa confortable utilisation de son système d'exploitation. Dans cet article, je tâcherais de vous présenter, dans les grandes lignes, le modèle de sécurité qu'utilise Windows, principalement les notions de privilège d'accès et de contrôle d'accès. De manière générale, lorsque je parlerais d'objet Windows, je parlerais d'utilisateurs, de machines, de fichiers, ou encore de processus. Contexte de sécurité Pour bien comprendre la suite, il est nécessaire de comprendre ce qu'est un contexte de sécurité chez notre ami Windows. Ce dernier désigne un ensemble d'attributs ou de règles de sécurité actuellement en vigueur pour reprendre la définition de Microsoft. Un contexte de sécurité se traduira par une structure de données particulières définis par la SSPI (\"Security Support Provider Interface\"), une API Windows écrite dans le but d'interagir avec le contexte de sécurité, elle est notamment utilisée, par exemple, pour l'authentification. Autrement dit, le contexte de sécurité définit les éléments de bases du système de sécurité de notre os favori (si c'est pas le cas faites comme si). SecurableObject Un objet est dit \"sécurisable\" s'il a la capacité de posséder un descripteur de sécurité. De manières générales, énormément d'objet dans Windows sont des SecurableObject . Les processus, les clés de registre, les fichiers/répertoires, les objets ‘Active Directory' et bien d'autres. Ils forment donc le cœur des interactions entre nous et le système d'exploitation. J'ai parlé des descripteurs de sécurité, ces derniers sont simplement des listes de plusieurs caractéristiques. Ils contiennent le SID (\"Security Identifier\", qui est un identifiant unique) du propriétaire de l'objet, le SID du groupe propriétaire, et des ACLs pour \"Access Control Lists\". Les descripteurs de sécurité sont usuellement au format SDDL (\"Security Descriptor Definition Langage\") bien que peu reluisant, il est en réalité très pratique car simple d'utilisation (non pas de compréhension). Token d'accès Lorsqu'un utilisateur Windows se connecte à son compte local (ou Active Directory) plusieurs informations seront alors stockés dans la mémoire. De manière assez évidente, il contiendra le condensat du mot de passe (sauf configurations très improbable ou un système relativement vieux et dans ces cas précis, ce sera le mot de passe en claire), son SID , le SID de son groupe, des privilèges d'accès (nous y reviendrons plus tard) et bien d'autres informations. On regroupe tout cela dans ce que l'on appelle un token d'accès. Ce dernier est alors gardé dans un processus un peu particulier appelé LSASS.exe pour \"Local Security Autority SubSystem Service\". Ce dernier est donc vital et très sensible. Lorsqu'on interagit avec le système d'une quelconque manière, une copie de notre token d'accès est alors utilisée. Dans le cas d'un fichier, les informations que le token d'accès contient vont donc être comparées avec les informations contenues dans la DACL (qui est une liste contenant les accès, plus d'information sur ce sujet un peu après) garantissant ou non un accès d'une certaine valeur. Il peut être destiné à de l'écriture, de la lecture ou bien même pour de l'exécution. Un cas plus intéressant est celui du démarrage d'un programme. En effet, ce dernier est lancé en tant qu'un utilisateur en particulier, il ne doit donc pas contourner ce fameux système d'accès. C'est pourquoi les processus sont considérés comme des SecurableObject , et dans cette situation, une copie de notre token d'accès est également donné et quand le programme interagira avec le système, il le fera bien selon les droits et l'identité de l'utilisateur connecté. La fonction CreateProcessA() est une fonction de l' API Windows kernel32.dll qui permet de créer un nouveau processus. Privilèges d'accès Comme mentionné plus tôt, le token d'accès renferme en son sein un certain nombre de privilèges. Ces derniers sont attribués à chaque connexion, en fonction des règles de sécurité. Plus précisément, les privilèges d'accès sont donnés en fonction du groupe d'appartenance auquel on attribut des droits par défaut grâce aux GPOs locales (dans gpedit.msc , Configuration Ordinateur \\ Paramètres windows\\ Paramètres de sécurité\\ Stratégies local\\ Attribution des droits utilisateur ). La liste de ces privilèges n'est pas présente sous forme d'énumération classique, en revanche voici une implémentation en PowerShell pour bien se rendre compte de l'ensemble de ces privilèges (issus de PSReflect-Functions ). $SecurityEntity = psenum $ENUM SecurityEntity UInt32 @{ SeCreateTokenPrivilege = 1 SeAssignPrimaryTokenPrivilege = 2 SeLockMemoryPrivilege = 3 SeIncreaseQuotaPrivilege = 4 SeUnsolicitedInputPrivilege = 5 SeMachineAccountPrivilege = 6 SeTcbPrivilege = 7 SeSecurityPrivilege = 8 SeTakeOwnershipPrivilege = 9 SeLoadDriverPrivilege = 10 SeSystemProfilePrivilege = 11 SeSystemtimePrivilege = 12 SeProfileSingleProcessPrivilege = 13 SeIncreaseBasePriorityPrivilege = 14 SeCreatePagefilePrivilege = 15 SeCreatePermanentPrivilege = 16 SeBackupPrivilege = 17 SeRestorePrivilege = 18 SeShutdownPrivilege = 19 SeDebugPrivilege = 20 SeAuditPrivilege = 21 SeSystemEnvironmentPrivilege = 22 SeChangeNotifyPrivilege = 23 SeRemoteShutdownPrivilege = 24 SeUndockPrivilege = 25 SeSyncAgentPrivilege = 26 SeEnableDelegationPrivilege = 27 SeManageVolumePrivilege = 28 SeImpersonatePrivilege = 29 SeCreateGlobalPrivilege = 30 SeTrustedCredManAccessPrivilege = 31 SeRelabelPrivilege = 32 SeIncreaseWorkingSetPrivilege = 33 SeTimeZonePrivilege = 34 SeCreateSymbolicLinkPrivilege = 35 } Et oui, 35 privilèges ça fait beaucoup. Mais à quoi servent-ils ? Ils permettent d'effectuer certaines tâches systèmes. Il ne faut donc pas les confondre avec les ACE (\"Access Control Entry\", qui représente un droit attribuer dans une DACL ), car ces dernières définissent l'accès à un SecurableObject . Par exemple, le droit SeBackupPrivilege est donné à tout membre du groupe Backup Operators et permet de lire le contenu d'un fichier peu importe ses ACLs (sauf si une interdiction explicite à votre encontre est présente). Le droit SeRestorePrivilege permet identiquement d'écrire un fichier. Le droit SeDebugPrivilege (réservé aux Administrateurs), permet d'accéder et de manipuler la mémoire d'un autre programme, un programme que nous n'avons pas lancé. C'est typiquement ce droit que demande Mimikatz pour accéder aux fameux condensats de mots de passe gardé par LSASS.exe . Vous pouvez trouver une liste complète des droits donnés par quel privilège dans la documentation officielle de Microsoft . Ces privilèges, sont donc naturellement très puissant et il ne faut surtout pas négliger leur sécurité, qui possède quoi. Bon, mais comment puis-je clairement savoir de quels privilèges je dispose ? La commande la plus simple pour cela est whoami /all . whoami.exe ouvre le token d'accès de son propre processus, or comme nous l'avons dit plus tôt, ce dernier contient toutes les informations dont le système à besoin pour achever ses tâches, notamment accéder aux SecurableObject . Ainsi, nous pouvons voir nos privilèges ( whoami /priv ), nos groupes ( whoami /groups ), notre SID ( whoami /user ) et bien d'autres. Un petit exemple, une fois connecté, je lance une invite de commande PowerShell et tape whoami /priv . Par malchance, le droit semble alors désactivé. Windows PowerShell Copyright (C) Microsoft Corporation. Tous droits réservés. Testez le nouveau système multiplateforme PowerShell https://aka.ms/pscore6 PS D:\\> whoami /priv Informations de privilèges ---------------------- Nom de privilège Description État ============================= ============================================ ========= SeShutdownPrivilege Arrêter le système Désactivé SeChangeNotifyPrivilege Contourner la vérification de parcours Activé SeUndockPrivilege Retirer l'ordinateur de la station d'accueil Désactivé SeIncreaseWorkingSetPrivilege Augmenter une plage de travail de processus Désactivé SeTimeZonePrivilege Changer le fuseau horaire Désactivé PS D:\\> Pour éteindre mon ordinateur je dois donc activer ce droit. Grâce à une magie occulte je peux l'activer (en réalité j'use simplement d'un implémentation de la fonction RtlAdjustPrivilege de NTDLL.dll , qui permet d'ajuster les privilèges pour notre processus, en PowerShell) et on peut alors voir que maintenant je peux éteindre mon poste. PS D:\\tools\\PowerShellScript\\PSReflect-Functions> RtlAdjustPrivilege -Privilege SeShutdownPrivilege -Verbose COMMENTAIRES : [RtlAdjustPrivilege] Attempting to enable 'SeShutdownPrivilege' for the current process COMMENTAIRES : [RtlAdjustPrivilege] enable for 'SeShutdownPrivilege' successful PS D:\\tools\\PowerShellScript\\PSReflect-Functions> whoami /priv Informations de privilèges ---------------------- Nom de privilège Description État ============================= ============================================ ========= SeShutdownPrivilege Arrêter le système Activé SeChangeNotifyPrivilege Contourner la vérification de parcours Activé SeUndockPrivilege Retirer l'ordinateur de la station d'accueil Désactivé SeIncreaseWorkingSetPrivilege Augmenter une plage de travail de processus Désactivé SeTimeZonePrivilege Changer le fuseau horaire Désactivé PS D:\\tools\\PowerShellScript\\PSReflect-Functions> Sauf qu'après une partie de \"CS:GO\" en compagnie d'une équipe russe le \"ragequit\" serait quelque peu ennuyant. C'est pour cela qu'il est possible d'activer ou de désactiver des privilèges. Attention, ces derniers doivent être contenu dans notre token d'accès initiale, sinon cela serait beaucoup trop facile. Lorsque nous utilisons un programme tel \"shutdown.exe\" il va utiliser certaines fonctions de la WinAPI ( AdjustTokenPrivileges de advapi32.dll pour les curieux) pour changer ses privilèges, et de ce fait pouvoir dire adieu à notre partie gagnée d'avance. Les listes d'accès Il en existe deux types. La première est la SACL pour \"System Access Control List\" qui est vraisemblablement la plus simple. En effet, elle permet d'établir un certain nombre de règles concernant l'audit d'accès à l'objet portant cette liste. On peut alors définir dans cette dernière quel événement, pour quel utilisateur, se doit d'être inscrit dans les journaux d'événements. L'autre type se nomme DACL pour \"Discretionary Access Control List\". La DACL contient un certains nombres d' ACE (\"Access Control Entry\") qui précise le type de droit accordé à un objet. Leur structure est assez élémentaire. En outre, une ACE contient un header déterminant son type c'est à dire accès autorisé ou refusé et d'autres informations. Le header, quant à lui, contient le droit garantit ou non. Ce droit est appelé masque d'accès. On énumère ce que l'on appelle les droits standards qui sont élémentaires: DELETE est le droit de supprimer l'objet, je vous l'accorde il n'était pas très complexe celui-là. READ_CONTROL est le droit de lire la SACL/DACL . WRITE_DAC est le droit de modifier les entrés de la DACL , c'est à dire ajouter des ACEs . WRITE_OWNER est le droit de modifier le propriétaire d'un objet, l'intérêt étant que ce dernier possède implicitement tous les droits souhaités. Ces droits standards permettent alors de construire ce que l'on appelle les droits génériques: GENERIC_READ permet, comme son nom l'indique, de lire les attributs et propriétés d'un objet. Si c'est un fichier par exemple, ce droit permet la lecture du contenu du fichier. Son équivalent sous linux est le flag \"r\". GENERIC_WRITE permet la modification des propriétés et attributs de l'objet. Pour continuer dans le précédent exemple, ce droit permet la modification de son contenu. Son équivalent sous linux est le flag \"w\". GENERIC_EXECUTE permet de lire les permissions d'un objet. Factuellement si c'est un programme, il permet de le lancer. Son équivalent sous linux serait le flag \"x\". GENERIC_ALL est la combinaison de ces droits. Attention cependant, il est sensiblement plus fort, dans de très rare cas. Il peut s'avérer que la combinaison GENERIC_READ/WRITE/EXECUTE n'est pas équivalente à GENERIC_ALL , il n'a donc pas d'équivalent dans le système au pingouin. Il en existe encore un grand nombre mais l'objectif n'est pas l'exhaustivité. Pour voir ces accès, il faut utiliser l'onglet sécurité des propriétés d'un objet. On peut également utiliser notre shell préférer aka PowerShell (là pour le coup, vous n'avez pas d'excuse car PowerShell c'est génial et opensource). Une commande particulière est destinée à cela: Get-Acl . Elle prend comme argument le chemin vers notre objet, -Path et ce sera globalement tout pour une utilisation simple. Le résultat retourné est alors une \"table\" ce qui est assez inconfortable. Pour s'affranchir de se problème d'affichage, on utilise un pipe | vers la commande Format-List (ou son alias fl ). On peut alors apercevoir entre autre le propriétaire du fichier dans notre cas, les accès accordés ainsi que le descripteur de sécurité au format SDDL . PS D:\\tools\\PowerShellScript\\PSReflect-Functions> Get-Acl .\\ | fl Path : Microsoft.PowerShell.Core\\FileSystem::D:\\tools\\PowerShellScript\\PSReflect-Functions Owner : DESKTOP-8Q2CUHH\\Lancelot Group : DESKTOP-8Q2CUHH\\Aucun Access : BUILTIN\\Administrateurs Allow FullControl BUILTIN\\Administrateurs Allow 268435456 AUTORITE NT\\Système Allow FullControl AUTORITE NT\\Système Allow 268435456 AUTORITE NT\\Utilisateurs authentifiés Allow Modify, Synchronize AUTORITE NT\\Utilisateurs authentifiés Allow -536805376 BUILTIN\\Utilisateurs Allow ReadAndExecute, Synchronize BUILTIN\\Utilisateurs Allow -1610612736 Audit : Sddl : O:S-1-5-21-1739485902-3336647338-3362325240-1001G:S-1-5-21-1739485902-3336647338-3362325240-513D:(A;ID;FA;;;BA)(A;OICIIOID;GA;;;BA)(A;ID;FA;;;SY)(A;OICIIOID;GA;;;SY)(A;ID;0x1301bf;;;AU)(A;OICIIOID;SD GXGWGR;;;AU)(A;ID;0x1200a9;;;BU)(A;OICIIOID;GXGR;;;BU) PS D:\\tools\\PowerShellScript\\PSReflect-Functions> Si vous souhaitez plus de précisions, je vous invite à lire mon article sur l'abus d'ACL en ActiveDirectory Résumons Lorsqu'un utilisateur se connecte à sa session, des informations seront gardées en mémoire dans un token d'accès. Lorsqu'il souhaite démarrer un programme, une copie de son token est donné. Si ce dernier interagit avec le système, il devra utiliser ses privilèges pour réaliser certaines opérations. S'il n'est pas tout le temps nécessaire de les utiliser, lorsque l'on souhaite accéder à un objet (fichier, processus …) notre token d'accès sert de carte d'identité qui sera comparer avec le contenu de la DACL du descripteur de sécurité de l'objet auquel le programme/utilisateur souhaite accéder. En fonction des différentes entrés dans la liste d'accès, il se verra refuser ou autoriser un certain accès. J'espère que vous comprenez mieux à présent la manière dont l'os de Microsoft gère les permissions. Si cet article vous a plu, je vous invite à consulter mes articles sur les privilèges d'accès ainsi que sur l'abus des ACLs en Active Directory (et oui même si utile aux défenseurs, ils sont aussi utile aux attaquants).","tags":"misc","url":"https://ilearned.eu.org/secu_windows.html","loc":"https://ilearned.eu.org/secu_windows.html"},{"title":"Comment fonctionne le protocole TLS","text":"TLS est un protocole que nous utilisons quotidiennement, il est notamment utilisé dans HTTPS pour sécuriser la connexion. TLS est le successeur de SSL, nous verrons prochainement pourquoi SSL a été abandonné au profit de TLS. Dans cet article, nous étudierons TLS1.3 qui est la dernière version du protocole sortie en 2018. TLS se base à la fois sur le chiffrement asymétrique et le chiffrement symétrique. Un échange de clé (appelé handshake ou poignée de main) a lieu au début de la connexion, une clé secrète est échangée de façon asymétrique, cette clé est ensuite utilisée pour chiffrer les données (du chiffrement symétrique donc). Voyons donc plus en détail comment se passe un handshake avec TLS1.3. Le client envoie donc dans un premier temps un **Client Hello** qui contient entre autre : Les différents protocoles cryptographiques (pour le chiffrement asymétrique et symétrique) qu'il supporte. Key Share qui correspond a la clé publique du client, vous vous demanderez surement comment le client peut bien envoyer sa clé publique s'il ne sait pas les protocoles que le serveur supporte, c'est une différence majeur par rapport à TLS 1.2, avec TLS 1.3 le client part du principe que le serveur supporte un certain nombre de protocoles et envoie sa clé publique pour un de ces protocoles, s'il s'avère que ce n'est pas le cas, le serveur va renvoyer un HelloRetryRequest ainsi que les protocoles qu'il supporte. Le serveur répond ensuite avec un **Server Hello** qui contient entre autre : Le Certificat TLS qui permet d'assurer l'authenticité du serveur. Le Certificate Verify qui correspond à la signature du handshake, il est utilisé pour s'assurer que le handshake n'a pas été modifié en cours de route (dans le cas d'un attaque Man In The Middle par exemple). Change Cipher Spec indique à l'autre participant le passage à un mode de chiffrement symétrique. Dans Key Share le serveur indique sa clé publique Finished indique enfin la fin du handshake pour le client. Le client envoie enfin pour terminer un Change Cipher Spec et Finished . Vous trouverez ici 📎 un pcap d'un requête avec TLS 1.3. En parcourant vous verrez que la version de TLS affichée est TLS 1.2, it's not a bug, it's a feature c'est en fait pour éviter que certaines middlebox de merde 😡 , utilisées notamment en entreprise pour espionner le trafic, bloquent le trafic pour des version de TLS au dessus de TLS 1.2. Des paires de clés publique/privée sont dérivées un clé secrète afin de chiffrer de façon symétrique les échanges. Nous détaillerons bientôt plus en détail ce fonctionnement au travers d'ECDH. Vous l'aurez sûrement remarqué, le nom de domaine est en clair dans les requêtes, à la base une fonctionnalité appelée ESNI (Encrypted Server Name Indication) qui permet de chiffrer le nom de domaine dans les requêtes aurait dû être implémentée dans TLS 1.3 mais ce n'est pas encore le cas, ESNI n'est qu'à l'état de draft … 😕 Une autre fonctionnalité importante dans TLS 1.3 est le 0 RTT, c'est une fonctionnalité très controversée car elle ne respecte pas le principe de forward-secrecy , si un attaquant arrive à trouver la clé utilisée pour le chiffrement symétrique, il pourra déchiffrer toutes les prochaines requêtes. Elle consiste, pour faire simple, à garder une même clé symétrique pour plusieurs échanges afin de reprendre un échange sans avoir à faire de handshake, mais cette fonctionnalité est une fausse bonne idée…","tags":"misc","url":"https://ilearned.eu.org/tls.html","loc":"https://ilearned.eu.org/tls.html"},{"title":"Sécuriser votre réseau local avec 802.1x","text":"En entreprise comme dans un réseau domestique, le contrôle d'accès au LAN (réseau local) est primordial pour garantir la sécurité des données transmises sur ce réseau, on connaît tous la classique authentification par mot de passe est la méthode d'authentification utilisée dans la grand majorité des points d'accès (= AP) grand publique, mais un simple mot de passe ne permet pas, par exemple, de donner des accès différents au réseau en fonction des utilisateurs, pour pallier à ce problème, le standard 802.1x a été créé, il est normalisé dans la RFC . Ce standard s'appuie sur le protocole EAP que nous allons détailler dans cet article. L'authenticator (un point d'accès wifi dans notre exemple mais la même chose peut être mis en place en Ethernet) est un intermédiaire entre l'utilisateur et l'authentication server, la majorité du temps un serveur RADIUS . Identity request correspond à la demande du username au client par l'authenticator Identity response est ce nom d'utilisateur, cette information est demandée pour permettre à l'Authentication Server de savoir quelle challenge demander, il existe plusieurs types de challenge en voici quelques-uns MD5 (simple mot de passe hashé avec MD5, cette méthode est controversée car MD5 n'est pas considéré comme sécurisé). SIM (authentification basée sur la carte SIM). NFC (authentification basée sur le protocole NFC, c'est par exemple utilisé sur les badges d'entreprise.) Le ou les challenges sont ensuite envoyés tour à tour dans des paquets Challenge Request .","tags":"misc","url":"https://ilearned.eu.org/802_1x.html","loc":"https://ilearned.eu.org/802_1x.html"},{"title":"Fonctionnement de RADIUS","text":"Une question se pose parfois, comment gérer facilement de l'authentification et des autorisations d'utilisateur sur un réseau avec plusieurs machines sans répliquer la liste d'utilisateur avec les propriétés unique à chacun sur chaque machine. Une solution pour ce genre de cas est RADIUS, c'est un protocole qui permet d'authentifier et de donner une liste de propriété pour un utilisateur. Un cas d'usage est par exemple un stockage réseau (aussi appelé NAS ). Le serveur NAS va demander l'utilisateur et le mot de passe au client, il va ensuite se connecter avec le serveur RADIUS pour valider l'authentification. À chaque requête le NAS transmet les identifiants que le client lui a envoyé afin de savoir s'il peut accéder à la ressource demandée. Le client RADIUS (ici le NAS ) doit s'authentifier auprès du serveur RADIUS, pour se faire il utilise un secret qui est partagé entre le serveur RADIUS et le NAS . Ce secret permet aussi de chiffrer les identifiants de l'utilisateur via un \" xor \", un xor est un moyen de chiffrer sur base d'une clé unique, on parle donc de chiffrement symétrique. La communication entre le serveur RADIUS et son client se base sur UDP (il peut aussi passer par TCP , mais nous n'en parlerons pas), le client doit donc être capable de gérer la retransmission dans le cas ou aucune réponse ne lui est accordée. La phase d'authentification du client se base sur un paquet contenant l'utilisateur et le mot de passe. Ce paquet est nommé Access Challenge , il contient par exemple l'attribut User-Name = ramle et User-Passsword = phrase-de-passe . Le client reçoit ensuite une réponse du serveur, si le client RADIUS n'est pas connu du serveur il ne recevra pas de réponse. Si le client est connu alors, le serveur peut répondre de 3 manières Access-Accept en cas d'identifiant valide Access-Reject en cas d'identifiant invalide Acces-Challenge si l'authentification requiert plus de paramètre, par exemple un code PIN ou un carte d'accès. La réponse du serveur inclut aussi des informations supplémentaire appelé attribut , ce champs peut contenir des informations sur l'adresse IP qui doit être assigné à l'appareil, à la VLAN dans le quel il doit se trouver et bien d'autre paramètre. Le paquet RADIUS se forme en plusieurs partie : Code : Il définit le type de paquet Identifier : Il identifie le paquet, ce mécanisme permet de détecter une duplication, ou de savoir à quelle demande correspond la réponse car la réponse garde le même identifiant que la demande. Authenticator : Il authentifie la demande du client ou du serveur Attributes : il permet de donner les attributs spécifiques au client La partie Authenticator du paquet dans la requête Access Challenge est intéressante à étudier, cette partie ne contient que 16bits et nécessite un haut taux de confidentialité car il contient le mot de passe utilisateur. On utilise xor et le secret évoqué plus haut, dans le cas ou le password est trop long, il est alors hashé en MD5 puis transformé via un xor . RADIUS gère aussi l'itinérance, le serveur RADIUS du réseau local fera donc un proxy pour renvoyer la requête au serveur qui gère l'utilisateur. Le canal peut être sécurisé de plusieurs manières, soit un tunnel chiffré entre les 2, ou bien en sécurisant le canal avec le protocole TLS. J'espère que cette article vous aura plus :), on se retrouve demain pour parler de 802.1x , un protocole utilisant RADIUS.","tags":"misc","url":"https://ilearned.eu.org/RADIUS.html","loc":"https://ilearned.eu.org/RADIUS.html"},{"title":"Comment fonctionne HTTP/3 ?","text":"Il n'y a pas longtemps nous avions découvert le fonctionnement d' HTTP , et différentes versions de ce protocoles, mais l'une d'elle n'a pas été vue : HTTP/3, cette version apporte un changement sur la méthode de transport en se basant sur QUIC qui lui même utilise UDP au lieu de TCP . Pour commencer, regardons de plus près QUIC, il existe pour le moment deux versions de ce protocole, une faite par Google qui n'a pas été standardisée, et une qui est en cours de rédaction pour être publiée sous forme d'une RFC à l'IETF (l'organe qui s'occupe de la publication des RFC). La version de Google se concentre sur HTTP/3, contrairement à la version de l'IETF qui veut faire de QUIC un protocole de transport servant pour d'autres usages que HTTP , pour le DNS par exemple. Pour le moment l'IETF (qui se base en partie sur les travaux de Google) est encore au stade de rédaction de la norme et se concentre sur HTTP/3 comme usage pour la première version. Cet article se basera sur les travaux de l'IETF et non ceux de Google. Pour commencer, QUIC se base sur UDP et veut résoudre certains problème de TCP , avec HTTP/2 par exemple, plusieurs transferts sont effectués sur un seul flux TCP , je vous renvoie vers l'article sur HTTP qui explique en détail ce concept, avec TCP si dans la liste des paquets en attente un paquet se perd tous les paquets avant celui perdu devront attendre le renvoi. On peut faire un parallèle avec un embouteillage de voiture, si une voiture bloque la route, celles qui précèdent la voiture devront attendre son passage. TCP rajoute aussi une latence importante due aux différents handshakes, UDP n'utilise pas de séquence de handshake. QUIC en rajoute pour assurer un minimum de fiabilité. On compte au total 4 aller-retours pour récupérer une page (ou un code d'erreur) contre 6 dans les versions d'HTTP basée sur TCP . Le client commence par l'envoi d'un \"hello\" pour donner différents paramètres sur lui, ensuite le serveur répond en envoyant directement le certificat et les informations pour commencer l'échange de donnée, le client envoie ensuite sa requête avec la méthode. Le client finit par y répondre par le code de retour ou la page demandée. QUIC fonctionne sur UDP comme dit plus haut, il force un certain niveau de sécurité en imposant TLS en version 1.3, pour les communications. Il offre aussi une certaine fiabilité qu'UDP ne possède pas, rappelez-vous, UDP ne vérifie rien. QUIC résout ce problème en ajoutant une couche qui permet de gérer une retransmission de paquet au cas où celui-ci se perdrait en chemin, il permet aussi un contrôle de la congestion, la congestion en réseau c'est la saturation du réseau en lui même, cela cause un ralentissement ou une perte de paquet dans les cas extrêmes, le protocole est donc pas loin de TCP sur la fiabilité. Sur un seul canal UDP , QUIC permet de faire placer plusieurs flux en simultané. Pour le moment, nous avons vu principalement QUIC, la raison est que HTTP/3 n'apporte pas grand chose, c'est HTTP/2 adapté pour passer au dessus de QUIC, il y a quelques différences mineures comme la compression des en-têtes qui est adapté au protocole, mais les modifications sont mineure et viennent surtout adapté HTTP pour QUIC. Le rapprochement avec HTTP/2 est plutôt logique d'ailleurs si on regarde la chronologie le travail sur HTTP/3 à commencé dans la même période. Un point utile à aborder est de savoir comment le client sait si il doit communiqué en HTTP/3 ou non. En effet, les anciennes version d'HTTP utilise TCP contrairement à HTTP/3 qui utilise UDP . Pour informer le navigateur de la présence d'HTTP/3 l'en-tête Alt-Svc à été crée, elle indique le port UDP sur le quel le client doit aller voir, on peut aussi via l'en-tête indiquer un domaine différent. L'amélioration qu'apporte HTTP/3 est relativement mineure mais se révèle assez utile, sur une connexion stable avec peu de perte de paquet la différence n'est pas forcément visible, mais sur un réseau saturé avec un grand nombre de perte ne pas renvoyer toute la queue à chaque perte est un gain non négligeable. Une observation faite par certains est que HTTP/3 demande plus de CPU pour le serveur, ça peut être un frein pour le déploiement. Il faut aussi gardé en tête que QUIC est assez nouveau, les implémentations ne sont pas encore parfaite, le temps dira si ce protocole vaut le coup ou non. Niveau performance, HTTP/3 apporte un gain au niveau de la latence grâce à la poignée de main réduite, pour ce qui est de la vitesse de chargement, la prioritisation des flux, et la possibilité d'envoyer sur plusieurs flux en simultané permet de gagner un peu. Selon Cloudflare HTTP/3 améliore le temps d'établissement de la première connexion de 12,4%, pour ce qui est du chargement d'une page, ici leur propre blog, le temps diminue entre 1 et 4%, c'est au final assez peu, mais sur une connexions assez lente quelques pour-cent n'est pas négligeable. Si vous regardez un peu en détail votre navigateur vous remarquerez qu'HTTP/3 n'est pas encore activé par défaut, en effet ce protocole bien que prometteur n'est pas encore standardisé et est très minoritaire. Si par curiosité vous voulez tout de même activé dans about:config sur votre firefox vous pouvez changez la configuration network.http.http3.enabled vers true . Sachez toutefois que des sites comme celui de Cloudflare où de Google intègrent déjà HTTP/3 ! J'espère que cet article vous aura plus :), on se retrouve demain pour parler de radius.","tags":"misc","url":"https://ilearned.eu.org/http3.html","loc":"https://ilearned.eu.org/http3.html"},{"title":"Sécuriser NTP, à quoi bon ?","text":"Nous avons vu jeudi comment fonctionne le protocole NTP mais il reste un dernier point à aborder, comment assurer l'intégrité des données transmises via NTP ? Vous vous demanderez sûrement, à quoi bon sécuriser le protocole NTP, alors qu'il ne transmet que le temps 🤔. Le temps est une donnée très importante en informatique, plus qu'on ne pourrait le penser de prime abord, il est utilisé dans de nombreux protocoles cryptographiques, comme par exemple dans TLS ou DNSSEC avec le système de TTL (time to live). Pour sécuriser NTP de nombreux protocoles ont été proposés et mis en place, nous en citerons ici trois. Le chiffrement symétrique Dans NTP3 est ajouté le système d'authentification par clés symétriques, un secret partagé est échangé la première fois entre le client et le serveur et c'est ce secret qui est ensuite utilisé pour sécuriser la connexion. Mais cette méthode pose un gros problème, il est nécessaire d'échanger une clé secrète la première fois, elle est donc très difficilement automatisable et impossible à déployer à grand échelle. Autokey Une autre approche a été autokey , ce système utilisé du chiffrement asymétrique et résous donc les problèmes qui se posaient avec le chiffrement symétrique, en partie seulement, car le protocole autokey a de grosses lacunes en terme de sécurité, un comble, effet la taille du cookie utilisé pour s'authentifier avec autokey est de seulement 32 bits, ce qui le rend très vulnérable, mais ce n'est pas le seul problème d'autokey, le client n'est identifié que par son IP, un attaquant pourrait donc se faire passer pour le client et dérober le cookie. Network Time Security (NTS) Pour pallier aux faiblesses de ces deux protocoles, un nouveau protocole est un cours de création, NTS (standardisé dans la RFC 8915 il se base sur le principe du chiffrement asymétrique sans les problèmes d'autokey. Ce protocole se base en partie sur TLS pour l'échange de clés, il utilise ensuite les parties des headers spécifiques à NTP pour sécuriser le reste de la connexion. C'est un protocole prometteur mais qui n'est malheureusement pas encore assez implémenté.","tags":"misc","url":"https://ilearned.eu.org/securiser_ntp.html","loc":"https://ilearned.eu.org/securiser_ntp.html"},{"title":"NTP, comment ça marche ?","text":"Depuis la démocratisation d'internet et de l'informatique en général, une question s'est posée, comment faire en sorte que les horloges de tous les ordinateurs soient coordonnées ? En septembre 1985 une première version du protocole NTP (Network Time Protocol) est publiée dans la RFC 958 , ce protocole se base sur UDP pour sa légèreté. NTP fonctionne sur une typologie de réseau dite mesh , elle est découpée en strates afin de délivrer un temps équivalent partout et d'assurer une redondance. Les serveurs de strate 1 sont les horloges principales, le temps qu'elles donne peut provenir de différentes sources comme le GPS ou une horloge atomique . Les serveurs des strates plus basse s'échangent entre eux leur temps afin de vérifier qu'il correspond bien. Quand nous, utilisateurs, accédons à un serveur NTP, on accède bien souvent à un serveur de strate 2 ou 3. Voici à quoi ressemble une requête NTP : Ça fait pas mal de parties 😄. Nous ne commenterons ici que les plus importantes. LI, Leap Indicator indique une seconde intercalaire imminente. Une seconde intercalaire correspond, pour faire simple, à une seconde ajoutée sur toutes les horloges occasionnellement afin de synchroniser le temps universel coordonné (UTC) avec le temps solaire. VN, Version Number indique simplement la version de NTP utilisée. Mode, indique le mode dans lequel est l'émetteur, client, serveur etc. Poll correspond à l'intervalle à laquelle le client doit reinterroger le serveur NTP. Root delay correspond au temps pour faire un aller-retour vers un serveur de strate 1. Et root dispersion est une estimation de la marge d'erreur du serveur de strate 1. Reference ID correspond au type d'outil utilisé par le serveur root (strate 1) comme par exemple le GPS ou une horloge atomique. Reference Timestamp est le temps de la dernière mise à jour via NTP. Les trois autres timestamps sont décris ci-dessous Le destination timestamp n'est logiquement pas inclut dans les headers, il est dans ce schéma à titre informatif. Ça fait beaucoup de paramètres 😅 Mais grâce à toutes ces informations on peut avoir une précision de l'ordre de quelques nanosecondes en soustrayant le temps de transfert ! Un dernier problème se pose, comment assurer le fait que le serveur NTP ne se fasse pas usurper ? Nous avons déjà étudié dans d'autres articles des moyens de signature cryptographique, NTP implémente aussi une solution de ce type que nous étudierons très prochainement :). Merci d'avoir lu cet article, j'espère qu'il vous a plu 😄.","tags":"misc","url":"https://ilearned.eu.org/ntp.html","loc":"https://ilearned.eu.org/ntp.html"},{"title":"Comprendre le protocole UDP","text":"Nous avions récemment vu le fonctionnement de TCP , ce protocole essaye d'avoir la meilleur fiabilité possible pour la transmission, mais un certain nombre d'échanges sont requis pour vérifier l'intégrité du flux ce qui rajoute de la latence qui dans certains cas, est problématique. UDP est un protocole qui tente de résoudre ce problème. UDP est l'acronyme de User Datagram Protocol (traduit par protocole de datagramme utilisateur), ce protocole se base sur IP et fait partie de la couche transport du modèle OSI . Contrairement à TCP il ne fait pas de \"poignée de main\" (ou handshake en anglais) et ne nécessite pas d'accusé de réception (ACK), cette manière de fonctionner le rend plus tolérant à un réseau défectueux et lui permet un latence plus faible. Il n'est utile que dans des cas où une perte de paquet ne pose pas un soucis important. UDP est utilisé dans certains protocole très utilisé comme NTP, DNS, ou plus généralement les applications qui ont besoins de temps réel comme les jeux vidéo ou certains services de streaming. Comme je l'ai dis plus haut UDP ne vérifie pas la bonne réception d'un paquet (contrairement à TCP avec son système d'ACK), la machine envoie donc le paquet sans forcément attendre un retour. Ce protocole est bien plus simple que TCP dans sa conception. Un paquet UDP se compose tel que décrit sur ce schéma : Comme on peut le voir, il y a un minimum d'information comparé à TCP, le port source qui permet si besoin de répondre, le port de destination, la longueur totale du segment UDP (données comprises), une somme de contrôle (hash) et les données en elle même, chaque entrée de l'en-tête fait 16 bits ce qui au total fait 64 bits pour la partie header contre 192 avec TCP ! La partie données a une longueur variable. Comme à notre habitude, regardons une capture réseau : On remarque directement la simplicité, 2 requêtes seulement pour un aller retour, chaque paquet est aussi assez léger, moins de 100 octets à chaque fois, pour ce qui est des nombres \"0.000000\" et 0.000093\" il s'agit du temps où ont été capturés chaque paquet. Si vous voulez regarder plus en profondeur la capture réseau, je vous laisse le fichier disponible ici . C'est tout pour cet article sur UDP, j'espère que vous l'aurez apprécié. On se retrouve demain pour parler de NTP :).","tags":"Today I Learned","url":"https://ilearned.eu.org/udp.html","loc":"https://ilearned.eu.org/udp.html"},{"title":"Décentraliser, une priorité","text":"Internet est un grand réseau de réseau tous interconnectés de manière différentes, la conception permet en théorie une redondance importante, mais dans les faits ce n'est pas forcément le cas. En effet, beaucoup de services sont concentrer sur un nombre retreint d'acteur La concentration de ressource chez un nombre restreint d'acteurs pose un soucis, si un acteur tombe au plus il est utilisé au plus le nombre de personnes impactées sera important, c'est ce pour quoi ne pas passer par les géants d'un secteur est un choix non négligeable, cela permet une meilleur redondance d'internet. Une autre problématique d'utiliser des gros acteurs est leur possibilité à imposer des conditions pas forcément éthique, par exemple Cloudflare, qui promet une protection contre les dénis de services, mais au vu du coups d'une infrastructure contre les attaques par déni de service leur service gratuit n'est en réalité qu'un bon coup de pub pour leur offres payantes, qui est devant un grand nombre de sites, dans un premier temps si ils tombent internet le ressent de manière exagérée, en plus d'empêcher une navigation agréable au utilisateur du réseau Tor. Qui je le rappelle, ne sert pas forcément qu'aux cybercriminels comme aime le faire croire certains article :), ce réseau sert aussi à contourner des blocage en vigueur dans certains pays, ou à éviter l'espionnage. Il n'y a bien sur pas que Cloudflare qui pose soucis, je les cites parce que je vois une recrudescence de son utilisation, qui, qui plus est n'est pas forcément justifié ou utile je vous invite à lire https://codeberg.org/crimeflare/cloudflare-tor.git . Bien sur ce ne sont pas les seuls, tous les grands acteurs comme Amazon avec AWS, Google avec GCP ou encore, bien que peu présent dans nos contrées, Alibaba Cloud. Il n'y a bien sur pas que l'hébergeur qui est important, mais les différents services qu'en temps qu'utilisateurs finaux nous sommes amenés à utiliser. Souvent ces outils sont très pratiques, mais que faire si celui ci n'est pas en ligne, l'entreprise disparait ou tout simplement supprime vos données ? Ce ne sont pas des cas inventés, pour ce qui est de l'indisponibilité on peut simplement observer les géants, Google avait une panne presque total à cause d'un quota (https://status.cloud.google.com/incident/zall/20013) de disque rempli. Pour ce qui est de la disparition de géant on peut regarde Yahoo, qui fut un temps était leader et n'est plus qu'un souvenir de nos jours. La suppression de contenu est un cas plus \"compliqué\" à aborder, souvent les conditions d'utilisations que vous acceptez en utilisant un service stipulent un grand nombre de raisons qui permettent sans trop de difficultés d'évincer un compte on peut prendre l'exemple de YouTube, bien connu pour ce genre de pratique, qui va jusqu'à fermer certaines chaines qui parlent de sécurité informatique, il y a aussi Github qui a supprimé youtube-dl de sa plateforme sur une demande illégitime, youtube-dl est de nouveau présent sur Github mais sans une communauté solide il est compliqué de contrer une telle suppression. Tout centraliser au même endroit pose aussi un soucis de vie privée, si par exemple vous avez vos mails, vos fichiers, votre agenda chez un seul acteur celui peut revendre ou utiliser ces données à des fin plus ou moins douteuses, et même si l'acteur est honnête, un pirate qui réussirait à s'introduire dans le système y trouverait une mine d'or pour usurper une identité, revendre à des agences de publicités etc. Après avoir parlé des problématique, il est intéressant de regarder les solutions. Pour ce qui est des réseaux sociaux il existe des alternatives comme Mastodon en équivalent à Twitter ou Facebook, pour Instagram je vous conseille Pixelfed et pour Youtube il y a PeerTube, ces solutions peuvent poser un problème, leur manque d'utilisateur mais ce n'est pas pour autant que aucun contenu de qualité y est présent, bien au contraire il y a beaucoup de contenu très qualitatif. Un soucis de ce genre de solution c'est l'hébergement, tout le monde n'a pas forcément l'envie de gérer soit même une instance, ou bien même la compétence. Pour palier à ça il y a un collectif : https://chatons.org qui liste un nombre d'association. Pour ce qui est du choix d'un hébergeur autre que les géants on peut regarder dans un premier temps les entreprises plus locales, par exemple ce blog est hébergé chez https://www.tetaneutral.net/ une petite association française, en hébergeurs plus \"business\" il y a en France de très bonnes entreprises, comme Scaleway ou OVH. J'espère que cette article plus politique est moins technique vous aura plus :). Nous aimerions remercier toutes les personnes suivant régulièrement ce blog, les statistiques sont incroyables, au début nous pensions juste avoir quelques visiteurs mais c'est tout le contraire qui s'est produit, encore hier nous avons plus de 300 personnes qui sont passées sur le blog et certains articles comme celui sur TCP a reçu plus de 1300 vues ! Les commentaires que vous laissez pour des corrections, ou des remerciements nous motivent aussi beaucoup, alors un grand merci 😊. Nous avons un dernier messages, poster tous les jours deviens de plus en plus compliqué surtout avec la reprise des cours en présentiel et la période d'examens qui approche, c'est pour cela que l'on passe maintenant à un post deux jours sur trois, au lieu de chaque jours. Ce qui fait que ce n'est pas demain qu'on se retrouve, mais mercredi pour parler de UDP .","tags":"misc","url":"https://ilearned.eu.org/decentralisation.html","loc":"https://ilearned.eu.org/decentralisation.html"},{"title":"Comment fonctionne le tracking par ETag","text":"De plus en plus de navigateurs mettent en place des mesures pour bloquer le tracking, Firefox par exemple, bloque par défaut les cookies third party. Pour contourner ces mesures de protection des utilisateurs, les entreprises de tracking sont à la recherche d'autres moyens de pister les utilisateurs, ETag est l'un d'eux. Nous en avons brièvement parlé dans l'article sur HTTP , l'en-tête ETag est dans le cas du serveur web Nginx que nous prendrons comme exemple ici, un condensat de la date de modification et de la longueur (lenght) du fichier demandé. Ce hash a été créé pour permettre au navigateur de savoir s'il y a eu des changements sur un fichier et s'il doit montrer la version du fichier conservée en cache à l'utilisateur ou télécharger à nouveau le fichier depuis le serveur. Ce système d'ETag peut cependant être détourné, afin de vérifier si les ETag correspondent, le client envoie l'ETag de la version qu'il a du fichier au serveur, le serveur peut donc, pour chaque utilisateur, servir un fichier différent (qui aura donc un ETag différent) et grâce à cet ETag savoir quel utilisateur a consulté quelle page à quelle moment. Des entreprises comme Hulu ou Spotify ont été épinglées pour avoir mis en place cette pratique, qui ne respecte évidemment pas le RGPD. Merci d'avoir lu cet article, en espérant qu'il a été clair :) On se retrouve demain pour parler de décentralisation !","tags":"misc","url":"https://ilearned.eu.org/etag.html","loc":"https://ilearned.eu.org/etag.html"},{"title":"Le fonctionnement d'HTTP","text":"Le web est l'usage le plus connu d'internet, un protocole assez vieux (mais pas aussi vieux qu'internet) se cache derrière ce succès : HTTP. HTTP est l'acronyme d'Hyper Text Transfer Protocol (protocole de transfert hypertexte si l'on traduit en français), il a été inventé pour palier à certains manques de FTP qui à l'époque était majoritaire, un des points principaux est la notion de format de données, c'est à dire indiquer au client quel est le type de donnée, cela permet au client de pouvoir interpréter et afficher sans demander à l'utilisateur ce qu'il doit faire de chaque fichier. Cette notion de \"format de données\" s'appelle le MIME. HTTP a connu plusieurs versions, l'initiale étant la 0.9 (notée HTTP/0.9) qui n'a jamais été standardisée dans une RFC, une RFC (pour request for comment, soit demande de commentaires en français) est un document technique identifié par un numéro définissant des procédures ou protocoles, ces documents sont accessibles sur https://www.rfc-editor.org/rfc/ (ou gemini://gemini.bortzmeyer.org/rfc-mirror/rfc-index.gmi via Gemini ), l'usage de cette version d'HTTP est assez marginal de nos jours. Quelques années plus tard est sorti au travers d'une RFC (la 1945 ) HTTP/1.0 cette RFC s'occupe surtout de préciser comment HTTP fonctionne, il n'apporte pas d'évolution avec la version 0.9. Assez rapidement HTTP/1.1 sort, cette version apporte certaines optimisations, comme l'envoi de plusieurs requêtes en simultané. Le fonctionnement d'HTTP se base sur le protocole TCP , par défaut le port utilisé est le 80. Pour demander ou envoyer des contenus on utilise des \"méthodes\", une méthode est une commande envoyée au serveur. On peut en citer plusieurs : GET : Demande une ressource HEAD : Demande uniquement les informations POST : Envoie des données La liste n'est pas complète, je vous laisse rechercher par vous même pour plus d'informations à ce propos ;). On peut regarder plus en profondeur HTTP en regardant les transmissions réseaux : La partie data, celle qui contient la page en elle même n'est pas directement visible ici, je vous laisse regarder le dump réseau sur wireshark, il est disponible ici . Un autre aspect intéressant d'HTTP sont les en-têtes (headers) qui donnent des informations au client à propos du serveur, et inversement. Côté client par exemple, on a l'en-tête \"Host\" qui donne le nom de domaine demandé par le client, cela permet de distribuer un contenu différent en fonction de celui-ci. Le serveur peut lui donner le type de contenu via \"Content-Type\". Il y a beaucoup d'autres en-têtes possibles, si vous voulez regarder celle d'une URL la commande curl le permet via l'option -I , pour https://ramle.be par exemple : % curl -I https://ramle.be HTTP/2 200 server: nginx date: Sat, 08 May 2021 14 :40:55 GMT content-type: text/html ; charset = utf-8 content-length: 1992 last-modified: Fri, 23 Apr 2021 18 :18:34 GMT vary: Accept-Encoding etag: \"60830f7a-7c8\" content-security-policy: default-src 'none' ; style-src cdn.ramle.be ; img-src cdn.ramle.be x-frame-options: SAMEORIGIN x-xss-protection: 1 ; mode = block x-content-type-options: nosniff referrer-policy: same-origin x-permitted-cross-domain-policies: master-only expect-ct: max-age = 60 , enforce permissions-policy: accelerometer =() , camera =() , geolocation =() , gyroscope =() , magnetometer =() , microphone =() , payment =() , usb =() strict-transport-security: max-age = 31536000 ; includeSubDomains ; preload accept-ranges: bytes On remarque sur la première ligne la version d'HTTP, ici c'est la version 2. On voit ensuite la liste des en-têtes : content-type indique le type de contenu (le MIME ) etag indique une suite de caractères ASCII, cette chaîne change si le contenu distant change, cela permet de mettre en cache les ressources. Il n'y a pas de méthode définie pour la génération de cette chaîne de caractères. Je n'ai décrit ici que les en-têtes qui me semblait importants pour cet article, beaucoup d'autres en-têtes restent très utiles mais moins utilisés, souvent orientés sécurité, certains feront surement l'objet d'un article prochainement ;). Si vous voulez des informations plus précises sur celle-ci je vous laisse aller voir la documentation de MDN qui est assez complète. J'ai cité plus haut la version 2 d'HTTP (notée HTTP/2) sans expliquer les changements apportés par cette version, nous allons donc dans ce paragraphe voir les différences avec HTTP/1.1, pour commencer l'implémentation faite par beaucoup de navigateurs impose le chiffrement via HTTPS (on reparlera plus bas d'HTTPS), un autre changement est dans le transport lui même, HTTP/1.1 se base sur du texte, là ou HTTP/2 utilise du binaire, ça le rends plus compact et facile à parser, mais non lisible par un humain sans outil spécifique. Il y a aussi un changement dans la connexion TCP elle même, au lieu de faire une connexion TCP par ressource, on utilise une seule connexion pour toutes les ressources le gain latence est assez important au vu du nombre d'aller-retour TCP . Vous avez probablement remarqué qu'HTTP ne présente presque aucun mécanisme de sécurité de base, il n'est en effet pas possible de vérifier l'authenticité des ressources ni d'empêcher un attaquant d'espionner la connexion, pour résoudre ce problème HTTPS est né, il s'agit simplement de faire passer HTTP via TLS, pour ce qui est de la vérification on se base sur les autorités de certification, contrairement à d'autres protocoles comme Gemini , je vous invite à aller voir l'article sur DANE pour plus de détails à propos des autorités de certification. HTTP permet de réduire la taille des données envoyées en les compressant, les deux algorithmes utilisés pour compresser les données sont gzip et brotli, le client peut dire au serveur lequel de ces algorithmes il supporte via l'en-tête \" Accept-encoding \". C'est tout pour l'article d'aujourd'hui, j'espère qu'il vous aura plus :), On se retrouve demain pour parler de radvd .","tags":"misc","url":"https://ilearned.eu.org/http.html","loc":"https://ilearned.eu.org/http.html"},{"title":"IPv6, il est grand temps de migrer","text":"Décembre 1998, c'est la date de parution de la RFC 2460 introduisant IPv6, aujourd'hui, seulement 26% des sites les plus visités en France sont accessibles en IPv6 d'après l'Arcep . Faisons donc un petit tour d'horizon de l'adoption d'IPv6. IPv6 a été créé pour répondre à une problématique simple, le manque croissant d'IPv4. En effet, avec IPv4 la quantité d'IPs total est théoriquement de 4 294 967 296 , théoriquement car certains blocs d'IPs sont réservés à des usages privés comme par exemple 10.0.0.0/8. Le nombre de 4 milliards d'IPs peut sembler énorme, mais cela ne représente qu'une IP pour deux personnes sur terre, de plus beaucoups d'IPs sont allouées (plus d'informations sur l'allocation des IPs ici 😉) mais pas utilisées, comme par exemple Apple qui monopolise un /8 soit 16 777 216 IPs qui n'est presque pas utilisé ! Avec IPv6 le nombre total d'IPs théoriquement disponible est de 340 282 366 920 938 463 463 374 607 431 768 211 456 , IPv6 permet donc largement de pallier à ce problème de pénurie d'IPv4. Une adresse IPv6 typique ressemble à ça 2a03:7220:8083:3c00::1 elle est codée sur 128 bits. Vous vous demandez sûrement ce à quoi correspondent les :: vers la fin de l'adresse, ils correspondent simplement à un remplissage avec des 0 afin d'atteindre le nombre de 128 bits. Par exemple : 2a03:7220:8083:3c00::1 correspond en réalité à 2a03:7220:8083:3c00:0000:0000:0000:0001 . Les opérateurs ont développé plusieurs techniques pour contrer à ce manque croissant d'IPv4, comme par exemple le CG-NAT, pour ceux qui ne le sauraient pas, le NAT c'est basiquement le fait de partager une seule IP publique entre plusieurs appareils (nous aborderons le NAT plus en détail plus tard ;)) le CG-NAT c'est donc du NAT mais à l'échelle d'une rue, d'un quartier. Le problème principal du NAT c'est qu'il empêche de nombreuses applications et protocoles de fonctionner, comme par exemple le Torrent ou même Google Maps ! Il empêche aussi d'héberger des services chez soi car seule une plage de ports est allouée au client, il faut donc avoir la chance de tomber sur la plage contenant les ports 80 et 443 pour pouvoir auto-héberger un site web par exemple. La solution à ces maux est donc IPv6, mais comme nous l'avons vu en introduction son déploiement prend du temps, beaucoup de temps, dans son rapport annuel l'Arcep pointait du doigt la lenteur du déploiement d'IPv6, surtout chez certains opérateurs, mais aussi chez de nombreux hébergeurs qui ne fournissent pas d'IPv6 par défaut à leurs clients ! Un des raisons de la lenteur du déploiement d'IPv6 est le fait qu'utilisateurs et hébergeurs se renvoient systématiquement la balle, les uns se demandant à quoi bon avoir de l'IPv6 si tous les sites qu'ils visitent sont disponibles en IPv4, les autres disant qu'il est inutile de déployer IPv6 puisque les clients ne sont en majorité pas équipés. Cette attitude dilatoire a pour conséquence de ralentir le déploiement d'IPv6 au détriment des petits hébergeurs associatifs qui n'ont pas forcément les moyens d'acheter des ranges d'IPv4 souvent très couteuses. Il existe un autre frein, et pas des moindres, au déploiement et l'utilisation massive d'IPv6, le réseau IPv6 est actuellement divisé en deux, en effet, Cogent un très gros fournisseur de transit refuse de peer (d'échanger ses routes) avec Hurrican Electric, un autre mastodonte du secteur. Ainsi, depuis le réseau IPv6 de Cogent il est impossible d'accéder à he.net (le site de Hurrican Electric) en IPv6. Ce bloquage dure depuis 2009, et malgré les nombreuses demandes de Hurrican Electric, ces deux entreprises ne parviennent pas à un accord financier. Nous finirons donc cet article sur ce joli gâteau, merci beaucoup de l'avoir lu, si vous souhaitez savoir si vous avez de l'IPv6 je vous invite à faire le test sur test-ipv6.com . Si vous n'en avez pas renseignez-vous, il existe probablement une démarche pour obtenir de l'IPv6 de la part de votre opérateur 😉, sauf si vous êtes chez orange, pas du bol :'(, il existe cependant des personnes qui offrent des tunnels IPv6 comme EnPLS par exemple.","tags":"misc","url":"https://ilearned.eu.org/ipv6.html","loc":"https://ilearned.eu.org/ipv6.html"},{"title":"Gemini, une alternative viable à HTTP ?","text":"Hey 👋, aujourd'hui on parle du protocole Gemini, Gemini est un protocole alternatif à HTTP ou Gopher pour ne citer qu'eux, créé en Juin 2019 avec pour objectif d'être beaucoup plus léger qu'HTTP, et de mieux respecter la vie privée des utilisateurs, en effet, avec Gemini, pas de JS, de cookies ou de eTag, le tracking des utilisateurs est quasi impossible. Gemini n'a pas été créé pour concurrencer HTTP mais bien pour offrir une alternative plus légère et sécurisée aux utilisateurs. Ce protocole embarque d'office le protocole TLS, il n'y a donc contrairement à HTTP pas la possibilité d'avoir des communications en clair. Ce protocole est basé en partie sur HTTP 0.9 et essentiellement textuel, mais des images peuvent aussi être intégré. Une requête Gemini est très simple, le client demande un fichier sur le serveur cible, le serveur répond avec un code d'erreur (ici, 20 = OK), le type de fichier, le plus souvent text/gemini et pour finir envoie le fichier. C'est plus simple que TCP avant-hier n'est-ce pas ? 😅 Voici donc une requête standard sur Gemini. C représente le client et S le serveur. C : gemini :// gemini . circumlunar . space /docs/ faq . gmi S : 20 text / gemini S : # Hey ! S : This is a website running under Gemini : D J'ai volontairement omis toute la partie correspondant à TLS dans l'exemple de requête ci-dessus car TLS fera l'objet d'un article plus complet dans peu de temps. Afin de se rendre indépendant de CA externes qui, comme on l'a vu sont un SPOF (single point of failure, point unique de défaillance) qui, si il se trouve compromit, pourrait délivrer des certificats frauduleux Gemini s'appuie sur le principe de TOFU, Trust on first use, c'est un méchanisme aussi utilisé par SSH par exemple, pour faire confiance à un certificat, le logiciel s'appuie simplement sur le certificat qu'il a croisé pour la première fois sur ce site. Cette façon de fonctionner est décriée par certains préférant un fonctionnement avec CA. Cependant, des mécanismes comme DANE couplé à DNSSEC existent et permettent de rendre relativement sécurisé Gemini. À l'occasion de ce post, j'ai rendu mon blog accessible sur Gemini, je vous invite à faire un tour dessus à l'adresse gemini://eban.bzh vous trouverez ici une liste de clients Gemini.","tags":"misc","url":"https://ilearned.eu.org/gemini.html","loc":"https://ilearned.eu.org/gemini.html"},{"title":"Le protocole IRC","text":"Hier nous avions vu le protocole TCP, aujourd'hui nous allons en reparler en l'appliquant concrètement. Le protocole que nous allons voir est IRC qui est très simple dans sa conception, ce qui permet de l'utiliser à la main sans se prendre trop la tête. IRC est l'acronyme d'Internet Relay Chat (traduit littéralement par relai de discussion internet), comme son nom l'indique, le serveur ne fait que relayer les messages, il ne les stocke pas contrairement à de nombreux autres protocoles de chat. Comme sous entendu juste au dessus, IRC fonctionne dans un mode client serveur, le client est identifié par un \"nick\" (diminutif de nickname, pseudo), personne n'aura donc le même nick sur un serveur IRC. Le nick est le seule moyens d'identification d'un client, pour éviter de se le faire voler il faut laisser un client tourner en continu. Ce fonctionnement n'est pas forcément pratique et facilite l'usurpation, pour palier à ça beaucoup de serveur donnent la possibilité de s'authentifier à l'aide d'un mot de passe soit via un bot à qui on doit envoyer un message spécifique contenant le secret, soit via un système appelé SASL qui permet d'envoyer directement le mot de passe durant la phase de connexion au serveur. Pour ce qui est de l'usage principal de IRC, c'est à dire les messages, on fonctionne via des canaux, un peu comme discord, identifiés par une chaine de texte commençant par \"#\", chaque canal peut posséder une description (cela reste facultatif). Pour essayer IRC on peut utiliser telnet qui est un outil qui permet d'établir des connexions TCP, on peut se connecter via la suite de commande : telnet irc.example.org 6667 USER utilisateur * * :Une description NICK utilisateur #Définit le fameux nick JOIN \\# canal #Pour joindre un canal PRIVMSG \\# canal Un message #Envoi \"Un message\" dans #canal # Le serveur réponds par le \"MOTD\" (messaye of the day, ou message du jour en français) Ce qui donnera la sortie : % telnet irc.lab.rameul.eu 6667 Trying 172 .17.0.2... Connected to irc.lab.rameul.eu. Escape character is '&#94;]' . :irc.lab.rameul.eu NOTICE Auth :*** Looking up your hostname... :irc.lab.rameul.eu NOTICE Auth :*** Could not resolve your hostname: Domain name not found ; using your IP address ( 172 .17.0.1 ) instead. USER ramle * * : NICK ramle :irc.lab.rameul.eu NOTICE Auth :Welcome to rml-lab! :irc.lab.rameul.eu 001 ramle :Welcome to the rml-lab IRC Network ramle!ramle@172.17.0.1 :irc.lab.rameul.eu 002 ramle :Your host is irc.lab.rameul.eu, running version InspIRCd-2.0 :irc.lab.rameul.eu 003 ramle :This server was created on Debian :irc.lab.rameul.eu 004 ramle irc.lab.rameul.eu InspIRCd-2.0 iosw biklmnopstv bklov :irc.lab.rameul.eu 005 ramle AWAYLEN = 200 CASEMAPPING = rfc1459 CHANMODES = b,k,l,imnpst CHANNELLEN = 64 CHANTYPES = # CHARSET=ascii ELIST=MU FNC KICKLEN=255 MAP MAXBANS=60 MAXCHANNELS=20 MAXPARA=32 :are supported by this server :irc.lab.rameul.eu 005 ramle MAXTARGETS = 20 MODES = 20 NETWORK = rml-lab NICKLEN = 32 PREFIX =( ov ) @+ STATUSMSG = @+ TOPICLEN = 307 VBANLIST WALLCHOPS WALLVOICES :are supported by this server :irc.lab.rameul.eu 042 ramle 476AAAAAK :your unique ID :irc.lab.rameul.eu 375 ramle :irc.lab.rameul.eu message of the day :irc.lab.rameul.eu 372 ramle :- :irc.lab.rameul.eu 372 ramle :- _ __ _ __ ___ | | _ __ ___ | | _ :irc.lab.rameul.eu 372 ramle :- | '__| ' _ ` _ \\| | _____ | ' _ \\ / _ \\ __ | :irc.lab.rameul.eu 372 ramle :- | | | | | | | | | _____ | | | | __/ | _ :irc.lab.rameul.eu 372 ramle :- | _ | | _ | | _ | | _ | _ | | _ | | _ | \\_ __ | \\_ _ | :irc.lab.rameul.eu 372 ramle :- :irc.lab.rameul.eu 372 ramle :- Description : Lab :irc.lab.rameul.eu 372 ramle :- NetAdmin : ramle :irc.lab.rameul.eu 372 ramle :- :irc.lab.rameul.eu 376 ramle :End of message of the day. :irc.lab.rameul.eu 251 ramle :There are 1 users and 0 invisible on 1 servers :irc.lab.rameul.eu 254 ramle 0 :channels formed :irc.lab.rameul.eu 255 ramle :I have 1 clients and 0 servers :irc.lab.rameul.eu 265 ramle :Current Local Users: 1 Max: 2 :irc.lab.rameul.eu 266 ramle :Current Global Users: 1 Max: 2 JOIN #article :ramle!ramle@172.17.0.1 JOIN :#article :irc.lab.rameul.eu 353 ramle = #article :ramle @ramle2 :irc.lab.rameul.eu 366 ramle #article :End of /NAMES list. PRIVMSG #article o/ :ramle2!ramle2@172.17.0.1 PRIVMSG #article :o/ ~~Pour ceux qui souhaiteraient tester par eux même avec telnet, le serveur IRC ne sera up qu'à partir de 21h30 ;).~~ Il est en ligne. On peut voir dans ce court exemple plusieurs choses, déjà la simplicité du protocole, en seulement 3 commande on rejoint un canal. Un autre fait qui peut être noté, c'est la commande envoyée pour définir le nom d'utilisateur : USER ramle * * : , il n'y a en effet pas de description, c'est une option facultative. Un autre point important est le symbole \"@\" devant l'utilisateur \"ramle2\", ce caractère signifie qu'il est \"op\" c'est à dire avec les permissions complète sur le canal, il peut donc expulser un membre, le bannir ou modifier des paramètres sur le canal, il ne peut par contre pas supprimer de messages vu que le serveur ne stocke rien, il ne sert que de relai entre les utilisateurs. Sur la capture réseau, on peut observer le peu de requête pour chaque étape, l'envoi du contenu en lui même et l'accusé. Si vous voulez observer par vous même, le fichier est ici irc.pcap C'est tout pour IRC, j'espère que ça vous aura plus. N'hésitez pas à poster en commentaire si vous avec des remarques, des questions, on se retrouve demain pour Gemini :)","tags":"misc","url":"https://ilearned.eu.org/irc.html","loc":"https://ilearned.eu.org/irc.html"},{"title":"Comprendre le protocole TCP","text":"Aujourd'hui on s'attaque à un gros morceau, le protocole TCP , vous êtes prêt·e·s ? C'est partit ! ;) TCP (= Transmission Control Protocol) est le protocole de couche 4 le plus utilisé et il fait partie intégrante de nos vies sans que nous ne nous en rendions compte. TCP a été créé afin de répondre à une problématique simple, permettre la communication de façon fiable entre deux machines. TCP est basé, comme de nombreux protocoles, sur une architecture client-serveur . Les données sont découpées en blocs appelés segments. La communication s'effectue en trois parties : l'établissement de la connexion, le transfert des données, la fin de la connexion. Commençons donc par l'établissement de la connexion, il est fait grâce à un handshake en trois étapes (Three-way handshake), la première étape est nommée SYN (synchronized), le client va donc envoyer un paquet SYN au serveur avec lequel il souhaite entamer la communication, il génère aussi aléatoirement un numéro de séquence qui est transmit dans ce paquet. Le serveur répond ensuite avec un paquet SYN-ACK (synchronize, acknowledge), littéralement accusé de réception de la demande de synchronisation , le numéro de séquence du serveur est généré aléatoirement, le numéro d'acquittement correspond au numéro de séquence du client incrémenté d'un. Pour finir, le client envoie un dernier paquet ACK au serveur pour confirmer qu'il a bien reçu le paquet SYN-ACK , le numéro de séquence de ce paquet est égal à celui généré par le client plus tôt + un, le numéro d'acquittement quant a lui est égal au numéro de séquence du serveur augmenté de 1. Ne vous en faites pas, nous allons voir plus précisément à quoi correspondent les numéros d'acquittement et de séquence ;). Une fois cette initialisation faite, la communication peut commencer, regardons donc de plus près le contenu d'un paquet TCP, accrochez vous il y a pas mal de contenu 😄. Cette partie s'appuie en grand partie sur l'article wikipedia de TCP . Nous ne détaillerons pas l'utilité de chacune de ces informations, seulement des plus importantes à nos yeux. Les numéros d'acquittement et de séquence sont deux valeurs aléatoires que l'on incrémente avec le nombre de données reçues afin de vérifier que tout les paquets sont bien arrivées dans l'ordre. Les numéros d'acquittement et de séquence initiaux sont générés aléatoirement durant la séquence d'initialisation de la connexion que nous avons vu plus tôt, le three way handshaking. Le partie \"Somme de contrôle\" est en fait un condensat des données transmises qui est calculé par le serveur et vérifié par le client afin de garantir l'intégrité des paquets. Si les hash correspondent on considère alors que le paquet a été transmit sans erreur. Le flag PSH (push) indique l'envoie de données. Le flag URG indique la présence de données urgentes. Le flag ECN/NS sert quant à lui à signaler la présence de congestion sur le réseau. Dans la partie Options on pourrait par exemple citer la MSS (Maximum Segment Size) qui correspond à la taille maximale de la partie data. Nous avons vu les parties les plus importantes d'un trame TCP, étudions maintenant comment fermer une session avec le protocole TCP. Pour fermer une session TCP, c'est relativement simple, le premier appareil envoie un paquet FIN au second avec son numéro de séquence, afin de vérifier que tous les paquets ont été reçu avant de fermer la communication. Le serveur répond alors avec un ACK pour confirmer la réception du message. Le même échange a ensuite lieu dans l'autre sens, le serveur envoie un paquet FIN et le client répond avec un ACK . Pfiou, ça fait beaucoup d'un coup 😅. Mettons maintenant tout ça en pratique, si vous êtes arrivé jusqu'ici, vous avez fait le plus dur, bravo 🎉. Vous remarquerez surement la présence des mentions de Win ; TSval et TSecr , regardons à quoi elles correspondent Win correspond à la fenêtre, pour faire simple, la taille maximale d'un paquet. TSval et TSecr sont simplement des timestamps , TSval correspond au moment de l'envoi du paquet et TSecr au moment de la réception, chacun des deux participants de la conversation peut soustraire ces deux valeurs pour déterminer le Round Trip Time (RTT) , le temps que prend un paquet à être échangé. Si vous souhaitez à votre tour inspecter ce simple échange tcp, le fichier est disponible ici , je vous recommande l'outil Wireshark si vous voulez inspecter des paquets de ce type. Vous l'aurez surement remarqué, le protocole TCP a été conçu dans l'optique de minimiser au maximum la perte de donnée, grâce à des fonctionnalité comme les accusés de réception ( ACK ) ou la somme de contrôle. Mais ces fonctionnalités posent un problème, les paquets s'en retrouvent alourdis, la partie somme de contrôle (checksum) pèse à elle seule 16 bits par exemple, autre exemple, pour chaque paquet d'envoie de données ( PSH ), un paquet ACK supplémentaire est nécessaire, à chaque fois ! Cette lourdeur pose notamment problème dans le cadre d'applications en temps réel, d'autres protocoles comme UDP que nous étudierons bientôt ont été créés pour remédier à ce problème. Merci beaucoup d'être arrivé jusqu'ici, cet article était plutôt complexe j'en suis conscient, si vous avez des question n'hésitez surtout pas à les poser, si vous souhaitez commenter n'oubliez pas que vous pouvez vous connecter (avec le bouton Log In ) via Github, Twitter et Gitlab. À demain 👋","tags":"Today I Learned","url":"https://ilearned.eu.org/tcp.html","loc":"https://ilearned.eu.org/tcp.html"},{"title":"Le soucis du DNS de son opérateur","text":"Le soucis du DNS de son opérateur Pour le moment, nous avons beaucoup abordé le DNS, avec différents moyens de sécuriser et les risques associés. Aujourd'hui, on va voir comment choisir correctement un résolveur, enfin pour être précis comment savoir le quel ne pas prendre. Je suppose que vous avez résolu le NDD (nom de domaine) blog.eban.bzh grâce au DNS distribué par votre box, il y a fort à parier que vous ne l'ayez pas changé et donc que ce soit votre FAI qui réponde aux requêtes, le problème étant que la plupart des gros FAI ne valident pas les requêtes via DNSSEC. Souvent, ces DNS mentent (envoient une réponse volontairement erronée, le plus plus souvent pour bloquer des sites.) sur base de demande faite par l'état, les listes sont d'ailleurs privées ce qui permettrai sans soucis de bloquer des sites totalement légitimes, c'est le cas de sci-hub par exemple, une plateforme qui partage des documents scientifiques. % dig @109.88.203.3 sci - hub . se A + short # DNS de VOO , un opérateur belge 54.36.19.166 # IPv4 redirigeant vers une page du gouvernement belge % dig A sci-hub.se +short #Utilisation d'un DNS propre 186.2 . 163.219 # IPv4 correct pour le site Il y a aussi un autre problème, la confidentialité. En effet, le serveur distant peut voir toutes les requêtes faites par un client, dans le cas d'un FAI il peut théoriquement savoir précisément qui vous êtes. Ils sont (obligation légal) déjà en possession de votre identité liée à l'adresse IP. Il reste peut probable que les FAI le fassent vraiment, ça leur rajouterai un coup conséquent pour le stockage de logs, sans oublier les risques de sanction si il n'est pas stipulé dans les CGU (conditions générales d'utilisation) ce stockage des requêtes. Il y aussi le problème de MITM, les DNS des opérateurs n'utilise pas de protocole comme DoH ou DoT, un pirate pourrait donc intercepter les requêtes. Dans cet article, on s'est concentré sur les opérateurs, mais ces problèmes existent sur beaucoup de résolveur publique qui bien souvent, offrent peu de garantie quand à la confidentialité, ou l'authenticité des réponses.","tags":"misc","url":"https://ilearned.eu.org/dns-fai.html","loc":"https://ilearned.eu.org/dns-fai.html"},{"title":"Usage des VLAN","text":"Souvent pour des raisons de sécurité ou par nécessité de priorisation du flux de certains appareils, il est nécessaire de séparer le réseau en différentes parties, pour par exemple, séparer un réseau d'administration de serveurs et du matériel réseau avec le réseau destiné aux machines d'une entreprise. Dans ce cas deux solutions sont possible, soit utiliser plusieurs interfaces réseaux, soit faire des VLANs. Les VLANs permettent de gérer de manière plus aisée de la segmentation de réseaux, le principe est de par exemple permettre à un switch réseau en fonction du port sur lequel est branché une machine d'être sur une VLAN différente, chaque VLAN possède un ID numérique pour l'identifier. Un autre concept intéressant des VLAN, c'est le trunk, cela permet de faire passer plusieurs VLAN sur un seul port en tagant les paquets. Ce tag est rajouté dans l'en-tête ethernet il contient l'ID de la VLAN dans laquelle le trafic doit aller. On peut aussi avoir des VLANs dites untagged, c'est à dire qui ne demande pas la modification de l'en-tête ethernet. Une VLAN untagged ne demande pas de configuration spécifique sur le client, c'est la VLAN \"par défaut\", contrairement à une VLAN tagged qui demande que le client rajoute l'information dans l'en-tête on ne peut donc avoir qu'une seule VLAN untagged. On peut prendre un exemple du quotidien, la box de votre FAI, si vous avez une box pour la TV par exemple, il y a de forte chance que ce soit une VLAN séparée, cela permet de prioriser le trafic de la box TV afin d'éviter des coupures si vous téléchargez de gros fichiers par exemple. Ici, VLAN 10 est un VLAN taged et VLAN 20 est untagged, tout les appareils passent de base par VLAN 20.","tags":"Today I Learned","url":"https://ilearned.eu.org/vlan.html","loc":"https://ilearned.eu.org/vlan.html"},{"title":"DANE et TLSA - Empêcher les certificats TLS frauduleux","text":"Aujourd'hui nous allons étudier le protocole DANE, ce protocole a été créé pour répondre à une problématique simple, comment garantir l'authenticité d'un certificat TLS si le CA est corrompu et délivre un certificat à, par exemple, un service de renseignement afin qu'il puisse intercepter et déchiffrer les requêtes des utilisateurs ? Cet exemple n'est pas pris par hasard, un cas similaire s'est produit en 2013 où l'ANSSI avait délivré des certificats pour des domaines de Google, probablement à des fins de renseignement. La RFC 6698 introduit donc le standard DANE (DNS Authentication of Named Entities) et le record DNS TLSA . Le principe est simple, ajouter un record dans la zone DNS qui contient un condensat du véritable certificat TLS, cette méthode ressemble très fortement au TLS Pinning, évoqué dans l'article d'hier mais a pour spécificité de placer le condensat au niveau du DNS. Voici un exemple de record pour blog.eban.bzh : _443._tcp.blog.eban.bzh. 10800 IN TLSA 3 1 1 D7DF5F6E8325454CF25B711D7FCB22CD639C4F26514E5473EC73C59353C16F0D On voit donc que l'on doit spécifier dans le record le port (ici, 443), le protocole utilisé (ici TCP, en passant, restez à l'affut dans les prochains jours un article à propos de ce protocole pourrait sortir 👀) puis le domaine auquel il s'applique, les trois numéros suivant 3 1 1 correspondent respectivement, à l'utilité du cadre d'utilisation de ce record, ici DANE-EE: Domain Issued Certificate un certificat donné pour un nom de domaine. Le 1 suivant indique le type de certificat hashé, 0 correspondant à un certificat fullchain et 1 à la clé publique uniquement, le dernier 1 correspond enfin à la fonction de hashage utilisée, ici SHA-256 . Une fois ce certificat mis en place le navigateur devrait, en principe, comparer ce hash avec un hash qu'il génèrerait de son côté, en principe car DANE n'est présent dans aucun navigateur grand publique . Il existe cependant le module DNSSEC/DANE Validator pour firefox et TLSA Validator pour chromium et dérivés. Pour résumer le fonctionnement de DANE, voici un petit schéma.","tags":"misc","url":"https://ilearned.eu.org/dane.html","loc":"https://ilearned.eu.org/dane.html"},{"title":"Fonctionnement du DNS over TLS et du DNS over HTTPS","text":"Hier on évoquait le problème de l'authenticité des réponses d'un serveur DNS. Nous avons vu la solution : DNSSEC mais ce mécanisme ne fait que signer les requêtes pour empêcher une modification, il n'empêche pas un espionnage passif des requêtes. Le risque d'espionnage demande de sécuriser le canal, deux solutions ont été retenues : DoT et DoH . DoT est l'acronyme de DNS over TLS, ce protocole est assez \"simple\" si on omet l'explication de TLS qui sera vue prochainement, c'est du DNS qui passe par un canal chiffré via TLS. On utilise TCP sur le port 853. Un soucis ce pose, TLS se base souvent, comme dans le monde du web avec HTTPS par exemple, sur des autorités de certification (abrégé CA) qui en théorie s'assure de délivrer des certificat qu'ils ont signés pour prouver la légitimité, mais en réalité ce système est assez peu fiable, il n'est en effet pas rare de voir une autorité délivrer par erreur ou même intentionnellement des certificats vérolés, qui n'aurait pas du sortir, de plus, historiquement un certificat coute assez chère, même si de nos jours certaines organisations comme Let's Encrypt délivre gratuitement un certificat TLS. Pour se passer de CA plusieurs solutions existent, la plus simple est tout simplement de ne pas vérifier le certificat, cela protège d'un attaquant \"passif\" mais Il reste relativement aisé de remplacer le certificat à la volé. Pour empêcher ce cas on peut faire de l'épinglage de clé, ce principe se base sur un condensat du certificat qui est ensuite mit en base64, le logiciel peut ensuite comparer le certificat distant avec la clé qu'il a en local si un pirate effectue une attaque de l'homme du milieu (MITM) et remplace le certificat en court de route le client se rendra compte du subterfuge. Un dernier problème dans DoT existe, un pare feu peut facilement en empêcher le fonctionnement, dans le cadre de portail captif par exemple souvent seul le trafic HTTP est autorisé. Une solution pour pallier à ce problème existe : DNS over HTTPS (DoH). DoH permet comme DoT de chiffrer le canal de communication, mais en passant par HTTPS l'avantage est qu'il est difficilement bloquable, en effet bloquer HTTPS bloquerai par la même occasion un grands nombres de sites web. Le fonctionnement reste axé sur le principe d'HTTP, l'avantage d'HTTP est le contrôle du cache directement sur le client avec l'en-tête Cache-Control: max-age=X (ou X est le temps en seconde). Comme pour DoT plusieurs choix existe pour la validité du certificat, ce sont les mêmes choix qui s'offrent à nous. Pour ce qui est des codes de retour du DNS ils sont dans le corps du message, et non sous forme de code HTTP, bien sur les codes classiques HTTP sont toujours appliqués. Ces deux méthodes peuvent poser soucis dans certains cadre, en effet, il est dans beaucoup de cas requis de passer par un programme qui \"traduit\" de DoH ou DoT vers le protocole DNS directement. Un exemple de logiciel est par exemple stubby sous Linux.","tags":"misc","url":"https://ilearned.eu.org/dot-doh.html","loc":"https://ilearned.eu.org/dot-doh.html"},{"title":"Fonctionnement de DNSSEC","text":"Petit rappel: ce blog a un flux RSS , n'hésitez pas à l'ajouter à votre lecteur de flux RSS favori :) Hier nous avons vu comment sécuriser la connexion entre un serveur slave et un serveur master, mais le problème d'authenticité des réponses se pose encore, pour commencer le trafic entre le serveur autoritaire et résolveur n'est pas chiffré, n'importe quel attaquant qui pratique une attaque type MITM peut donc modifier les réponses. Le canal n'est pas le seul problème, surtout qu'il est déjà possible de sécuriser le canal entre résolveur et autoritaire, et entre le résolveur et le client via DoT (DNS over TLS) et DoH (DNS over HTTPS), nous en parlerons plus largement demain ;). Sécuriser le canal si le serveur est corrompu ne sert pas à grand chose, c'est la raison pour laquelle DNSSEC ( RFC 4033 ) a été inventé. DNSSEC est une manière de signer de façon cryptographique une zone DNS sur base d'un système de clés asymétriques, un système de clés asymétriques repose sur 2 clés, une privée qui est gardée précieusement et qui sert à signer ou déchiffrer des données et une publique qui sert à vérifier ou chiffrer des données. Dans le cadre du DNSSEC le chiffrement ne sert pas, la clé privée sert donc uniquement à signer. Pour procéder on utilise en général deux pairs de clés : la KSK (key-signing key) et la ZSK (zone-signing key). La clé KSK est seulement là pour la signature de la ZSK, on lui donne une durée de vie plus grande que la ZSK et elle peut être stockée et générée hors ligne pour accroitre la sécurités de celle ci, l'avantage de ce système est de pouvoir garder plus longtemps la même clé sans rajouter trop de risque de fuite vu que stockée hors ligne, dans un lieu sécurisé. La ZSK quand à elle est sert à signer la zone, elle doit donc être présente sur la machine qui génère la zone, on la change plus souvent pour éviter les risques de fuites. Les serveurs esclaves n'ont besoin d'aucune des 2 clés, ils reçoivent directement la zone signée, la modification de la zone de leur part n'est donc plus possible si le résolveur vérifie avec DNSSEC. DNSSEC ne signe pas la zone de manière entière, mais signe chaque enregistrement indépendamment, la signature est contenue dans le record de type RSSIG . Ce fonctionnement pose un soucis si il permet de signer une entrée DNS, comment prouve t'on inexistante d'un enregistrement ? Pour résoudre cette problématique l'enregistrement de type NSEC existe. NSEC est un moyen de prouver l'inexistence (symbolisé par le code de retour NXDOMAIN ) d'un record en donnant le prochain (par ordre alphabétique) enregistrement de la zone, un problème de confidentialité se pose avec cet méthode, il est en effet très simple d'énumérer la liste d'enregistrement. Pour empêcher ce type d'attaque NSEC3 est né, au lieu de donner le FQDN on ne retourne que le condensat, l'énumération devient donc impossible. Une dernière problématique, et pas des moindres existe, comment s'échanger de manière fiable les clés à grande échelle ? On ne peut pas se les donner de personne à personne, c'est ingérable au vu du nombre de zones présentes sur internet. Pour résoudre cette problématique deux enregistrements existent : DS et DNSKEY. Commençons pas DNSKEY, il permet d'enregistrer la clé publique qui signe la zone, cette enregistrement est stocké dans la zone elle même. Avec uniquement DNSKEY on ne peut pas valider correctement la zone, la fiabilité de la chaine n'est pas garantie, il slave pourrait modifier ce record pour modifier la zone à sa guise, pour vérifier il existe donc un enregistrement DS qui se situe dans la zone parente et permet de faire une référence à la clé publique utilisée pour signer la zone du FQDN, c'est le registrar qui s'occupe de faire placer cet enregistrement. Pour ce qui est de la zone . il est impossible de définir un record DS au dessus, car c'est la zone la plus basse, l'IANA donne donc la clé utilisée et c'est disponible ici : https://www.iana.org/dnssec/files . C'est tout pour cet article, j'espère que ça vous aura plus. Si vous avez des remarques ou questions n'hésitez pas en commentaire. On se retrouve demain pour parler de DNS over TLS et DNS over HTTPS :)","tags":"misc","url":"https://ilearned.eu.org/dnssec.html","loc":"https://ilearned.eu.org/dnssec.html"},{"title":"Comment sont allouées les adresses IPs","text":"Internet est un énorme \"réseau de réseaux\" et comme toute grande organisation son fonctionnement est relativement complexe, aujourd'hui nous allons tenter de décrypter le fonctionnement de l'allocation d'adresse IP sur Internet 🙂. Vous commencez à avoir l'habitude, commençons par un schéma. À la tête d'Internet, il y a une organisation, l'ICANN (Internet Corporation for Assigned Names and Numbers soit Société pour l'attribution des noms de domaine et des numéros sur Internet en français) cette entreprise américaine gère les noms de domaine et les adresses IPs via l'IANA qui est un département de cette institution. Les IPs sont ensuite redistribuées entre cinq organisations appelés RIRs, L'ARIN pour les pays d'Amérique du nord. À qui l'IANA attribue 93 /8 Le LACNIC pour les pays d'Amérique du sud. À qui l'IANA attribue 10 /8 L'AFRINIC pour les pays d'Afrique. À qui l'IANA attribue 42 /8 Le RIPE NCC pour l'Europe et le Moyen-Orient? À qui l'IANA attribue 6 /8 L'APNIC pour l'Asie et le Pacifique. À qui l'IANA attribue 51 /8 On remarque donc de grandes inégalités dans l'allocation des IPs entre les RIRs. Ces RIRs attribuent ensuite eux même des plages d'IPs à de LIRs (Local Internet Registry ou registre Internet local), nous prendrons ici l'exemple de iFog GmbH qui est un LIR déclaré après du RIPE NCC. Les LIRs sont des intermédiaires entre les RIR et les AS. Nous en venons donc à notre dernier point, les AS (Autonomous System) sont des entités identifiées par un numéro de 32 bits (ou 16 avant 2007 ou dans certains cas aujourd'hui), ces numéros sont appelés ASN (Autonomous System Number), promit c'est le dernier acronyme 😛, ce sont ces AS qui peuvent avoir des ranges d'IPs, par exemple l'AS213253 a le range 2a0c:9a40:81fb::/48 qui lui est attribué par l'intermédiare d'iFog GmbH, cette AS possède aussi 2a0e::fd45::2a00::/40 qui lui est attribué par un autre LIR : Bakker IT. Il faut savoir qu'un AS est couteux, pour vous donner un ordre d'idée le coût approximatif d'un AS à l'année est d'environ 4000€ en prenant en compte le transit, les IPs etc. Merci d'avoir lu cet article qui, je l'espère vous aura éclairé sur le fonctionnement d'Internet ;) Si vous avez des questions n'hésitez pas à les formuler dans les commentaires, on se retrouve demain pour parler de DNSSEC.","tags":"misc","url":"https://ilearned.eu.org/allocation-ips.html","loc":"https://ilearned.eu.org/allocation-ips.html"},{"title":"Sécuriser la connexion entre Master et Slave","text":"Comme nous l'avons vu hier , la communication entre master et slave est faite en claire ce qui peut représenter une problème de sécurité, plusieurs systèmes ont donc été mit en place afin de sécuriser ce système. Le filtrage par IP Le moyen le plus courant pour filtrer les demandes de transfert de zone est le filtrage par IP, mais il présente deux inconvénients principaux, ce filtrage par IP peut poser problème dans le cas où le slave aurait un IP dynamique et pose aussi un problème de sécurité dû au fait qu'une IP puisse être \" spoofé \" (= usurpée), ce type d'attaque fera très probablement l'objet d'un article dans un futur proche 😉. Le protocole TSIG Le protocole TSIG , introduit en Mai 2000 par la RFC 2845 (pour info, une RFC, requests for comments, est un documents qui détaille le fonctionnement d'Internet ou de différents matériels informatique) permet d'authentifier un slave grâce à un secret partagé, le slave envoie un premier paquet contenant un condensat (hash) de la clé, le master compare alors ce hash avec celui qu'il génère aussi de son côté à partir de cette même clé, s'ils correspondent et que les id (= nom de la clé) sont identiques le slave est authentifié, pour résumer cela, voici un schéma. Ce protocole a cependant deux tares, premièrement, la clé doit être partagée pour la première fois de façon sécurisée, ce qui n'est pas toujours chose facile, deuxième tare, l'authentification est bien sécurisée, mais c'est moins le cas pour les requêtes AXFR/IXFR qui sont seulement signée, ainsi, l'intégrité de la réponse peut être assurée mais son contenu transite en clair sur internet, il existe cependant un autre projet de protocole qui pourrais permettre de sécuriser ces échanges. XFR over TLS Le protocole XoT (XFR over TLS) est encore à l'état de \"draft\" (brouillon) mais il permettrait de pallier à ce problème en chiffrant les requêtes grâce au protocole TLS. Il existe malgré tout une implémentation expérimentale de XoT dans le logiciel Bind , XoT est donc un protocole très prometteur afin de garantir la confidentialité des transferts de zone. Merci d'avoir lu cet article, on se retrouve demain pour parler de l'allocation des adresses IP sur internet🙂.","tags":"Today I Learned","url":"https://ilearned.eu.org/tsig-xot.html","loc":"https://ilearned.eu.org/tsig-xot.html"},{"title":"Communication entre Master et Slave - Vulnérabilité transfert de zone","text":"Aujourd'hui, on parle des procotoles AXFR et IXFR ainsi que de la vulnérabilité que peut représenter un transfert de zone non autorisé ! AXFR est un protocole qui sert à faire des transferts de zone du master vers le slave , le slave vérifie périodiquement si le serial (=numéro de version, voir ici si vous ne vous rappelez plus de ce que c'est) de son SOA est inférieur à celui du master , si c'est le cas, il fait une demande de transfert de zone, qui peut être fait grâce au protocole AXFR. Concrètement le master envoie simplement une copie de sa zone DNS vers le slave . Il existe aussi un autre protocole pour le même usage appelé IXFR, avec IXFR, si le slave remarque que son serial est inférieur à celui du master , il envoie le serial de la version de la zone qu'il détient au master , le master envoie ensuite le nouveau serial et deux listes, une pour les records à supprimer et une autre pour les records à ajouter/modifier. IXFR a pour avantage principal de nécessiter moins de bande passante qu'AXFR. Un fois ces petites explications faites, passons à la partie la plus intéressante, l'exploitation d'un transfert de zone :p. Pour authentifier un slave on effectue souvent un filtrage par IP, néanmoins il arrive que ce filtrage ne soit pas mit en place, n'importe qui peut alors dumper (= avoir une copie) de la zone très facilement, voici un exemple que vous pouvez essayer de reproduire chez vous. Nous allons dans un premier temps demander à notre serveur DNS résolveur la liste des serveurs DNS autoritaires pour le domaine zonetransfer.me . L'option +short que j'ai ajouté ici permet simplement d'avoir directement le résultat sans d'autres informations. ➤ dig zonetransfer.me NS +short nsztm1.digi.ninja. nsztm2.digi.ninja. Nous avons donc ici les deux serveurs DNS autoritaires du nom de domaine zonetransfer.me . Essayons donc de faire une requête DNS de type AXFR sur un de ces deux serveurs. ➤ dig axfr @nsztm2.digi.ninja zonetransfer.me ; <<>> DiG 9 .11.28-RedHat-9.11.28-1.fc33 <<>> axfr @nsztm2.digi.ninja zonetransfer.me ; ( 1 server found ) ;; global options: +cmd zonetransfer.me. 7200 IN SOA nsztm1.digi.ninja. robin.digi.ninja. 2019100801 172800 900 1209600 3600 zonetransfer.me. 300 IN HINFO \"Casio fx-700G\" \"Windows XP\" zonetransfer.me. 301 IN TXT \"google-site-verification=tyP28J7JAUHA9fw2sHXMgcCC0I6XBmmoVi04VlMewxA\" zonetransfer.me. 7200 IN MX 0 ASPMX.L.GOOGLE.COM. zonetransfer.me. 7200 IN MX 10 ALT1.ASPMX.L.GOOGLE.COM. zonetransfer.me. 7200 IN MX 10 ALT2.ASPMX.L.GOOGLE.COM. zonetransfer.me. 7200 IN MX 20 ASPMX2.GOOGLEMAIL.COM. zonetransfer.me. 7200 IN MX 20 ASPMX3.GOOGLEMAIL.COM. zonetransfer.me. 7200 IN MX 20 ASPMX4.GOOGLEMAIL.COM. zonetransfer.me. 7200 IN MX 20 ASPMX5.GOOGLEMAIL.COM. zonetransfer.me. 7200 IN A 5 .196.105.14 zonetransfer.me. 7200 IN NS nsztm1.digi.ninja. zonetransfer.me. 7200 IN NS nsztm2.digi.ninja. J'ai volontairement coupé une bonne partie de la réponse car elle serait trop longue sinon. Nous pouvons donc voir que nous arrivons à avoir une copie de la zone DNS complète, copie que nous ne devrions normalement pas avoir car elle peut comporter des informations sensibles comme par exemple des sous-domaines censés rester en interne ou des record PTR (les enregistrements PTR associent une IP à un nom de domaine) qui permettraient de trouver des IPs à analyser. Et voilà concrètement ce que donne une requête AXFR sur le réseau : 10 .2.0.2.36871 > 34 .225.33.2.53: Flags [ P. ] , cksum 0xa73b ( correct ) , seq 1 :59, ack 1 , win 502 , options [ nop,nop,TS val 3406917213 ecr 943752624 ] , length 58 38384 [ 1au ] AXFR? zonetransfer.me. ( 56 ) 34 .225.33.2.53 > 10 .2.0.2.36871: Flags [ . ] , seq 1 :1441, ack 59 , win 489 , options [ nop,nop,TS val 943753618 ecr 3406917375 ] , length 1440 38384 *- 51 /0/1 zonetransfer.me. SOA nsztm1.digi.ninja. robin.digi.ninja. 2019100801 172800 900 1209600 3600 , zonetransfer.me. HINFO, zonetransfer.me. TXT \"google-site-verification=tyP28J7JAUHA9fw2sHXMgcCC0I6XBmmoVi04VlMewxA\" , zonetransfer.me. MX ASPMX.L.GOOGLE.COM. 0 , zonetransfer.me. MX ALT1.ASPMX.L.GOOGLE.COM. 10 , zonetransfer.me. MX ALT2.ASPMX.L.GOOGLE.COM. 10 , zonetransfer.me. MX ASPMX2.GOOGLEMAIL.COM. 20 , zonetransfer.me. MX ASPMX3.GOOGLEMAIL.COM. 20 , zonetransfer.me. MX ASPMX4.GOOGLEMAIL.COM. 20 , zonetransfer.me. MX ASPMX5.GOOGLEMAIL.COM. 20 On voit donc que les informations transitent en clair (= non chiffrées) sur le réseau. C'est tout pour aujourd'hui merci beaucoup d'avoir lu cet article, n'hésitez pas à laisser un commentaire si vous avez des remarques à faire dessus, on se retrouve demain pour parler de comment sécuriser la communication entre master slave . 👋","tags":"Today I Learned","url":"https://ilearned.eu.org/xfr-zone-transfer.html","loc":"https://ilearned.eu.org/xfr-zone-transfer.html"},{"title":"Le principe de Master/Slave - Le rôle du registrar","text":"Aujourd'hui, on parle du rôle d'un Registrar puis dans une seconde partie du principe de Master/Slave dans le cadre de serveur DNS autoritaire. Les registrars ou bureaux d'enregistrement en français sont des organisations qui gèrent les domaines de premier niveau (TLD). On peut citer par exemple EURid qui gère le .eu , DNS Belgium pour le .be ou encore l'AFNIC pour le .fr . Ces registrars obtiennent leurs domaines de premier niveau auprès de l'IANA. je suppose que vous vous demandez ce qu'est l'IANA ? L'IANA est une branche de l'iCANN, c'est la branche qui gère l'attribution de ressource comme les blocs d'IP ou les TLD. Pour ce qui est de la revente de domaines, souvent les bureaux d'enregistrements passent par des sous-traitants, ces sous-traitants doivent respecter certaines règles comme par exemple un prix fixe reversé au registrar, ou des restrictions géographiques. Le principe de Master/Slave Le principe de master et de slave est assez important dans le monde du DNS et de l'informatique en général, il permet, dans le cadre du DNS, de redonder facilement une zone sur plusieurs serveurs autoritaires. Le serveur dit master (maître) est celui qui contrôle la zone, il possède le fichier \"original\". Dans certains contextes, comme pour éviter la corruption de tous les serveurs en cas d'erreur sur le maître, on utilise plusieurs serveurs masters, il n'y a plus une seule zone \"original \" mais plusieurs, le désavantage d'un tel système c'est qu'on est obligé de mettre à jour chaque serveurs master manuellement . Le serveur dit slave (esclave) est celui qui reçoit la zone depuis un serveur master, ce transfert de zone DNS utilise des protocoles comme AXFR ou IXFR mais ça c'est pour demain 😉. Ce concept de master/slave permet de redonder une zone bien plus facilement que si on le faisait manuellement.","tags":"misc","url":"https://ilearned.eu.org/master-slave-registrar.html","loc":"https://ilearned.eu.org/master-slave-registrar.html"},{"title":"Les bases du DNS","text":"Pour ce premier post dans la catégorie Today I Learned , on repart des bases, aujourd'hui on parle de DNS 😄. Pour les lecteurs les plus expérimentés connaissant déjà bien les bases du système de DNS, rendez-vous demain 😉. Les prérequis pour aborder cet article sont : des petites bases de réseau , la notion d'IP, de nom de domaine, et ça devrait suffire :) Vous trouverez à chaque fois en début d'article une petite \"carte mentale\" représentant les sujets que nous aurons déjà abordé en lien avec cet article, afin que vous puissiez avoir un accès plus facile aux pré-requis il suffit de cliquer sur le nom de l'article ou de la notion dans le schéma pour avoir le lien. Le DNS (Domain Name System) est un protocole permettant de \"traduire\" un nom de domaine en une adresse IP . Il existe deux types de serveurs DNS, les serveurs DNS résolveur, aussi appelés récurseurs (comme 1.1.1.1 ou 80.67.169.40 par exemple) servent à \"traduire\" un nom de domaine en adresse IP, et les serveurs DNS autoritaires, ce type de serveur DNS \"fait autorité\" sur une zone DNS (une zone DNS c'est l'ensemble des enregistrement DNS, une sorte de base de donnée qui fait la relation entre nom de domaine et IP), c'est à lui que vont se référer les serveurs DNS résolveurs pour associer nom de domaine et IP. Ça fait beaucoup de termes d'un coup 😅 pour rendre ça plus clair voici un petit schéma et les définitions. DNS Domain Name Système, protocole servant à traduire un nom de domaine en une adresse IP Zone DNS Ensemble des enregistrement DNS, sorte de base de donnée qui fait la relation etre nom de domaine et IP Serveur DNS récurseur Serveur DNS \"intermédiaire\" qui fait office de passerelle etre les serveurs DNS autoritaires et l'utilisateur Serveur DNS autoritaire Contient tout les enregistrement DNS d'une zone. Vous l'imaginez bien, les informations ne sont pas stockées tel-quel sur les serveurs DNS, ils sont stocké sous forme d'enregistrement DNS, en voici un exemple commenté tout droit tiré de mon propre serveur DNS autoritaire. eban.bzh. 1800 IN A 89.234.156.60 eban.bzh. correspond au domaine que nous avons demandé, vous vous demanderez sûrement, mais pourquoi y a-t-il un . à la fin ? Comment ça vous ne vous êtes pas posé la question ? 😛 En fait, la résolution des DNS fonctionne sous forme de couches, voici un petit schéma qui explique tout ça Les serveurs DNS \"root\" correspondent à la première couche, ils contiennent les records DNS pour tous les TLD Un TLD ? Quèsaco ? Un TLD (Top level domain name) c'est en fait tout les . quelque chose que vous rencontrez au quotidien, bzh , fr , com , be en sont quelques exemples. Les serveurs DNS root contiennent donc les record correspondants aux TLD. Les TLD, bzh. dans notre exemple, contient quant à lui les informations sur les domaines de sa zone, *.bzh. . eban.bzh. pour finir contient tout les records pour eban.bzh. et tout ses sous-domaines ( git.eban.bzh. , blog.eban.bzh. …) cette \"couche\" est appelée FQDN (Fully Qualified Domain Name). Pour rendre tout ça plus simple voici (à nouveau :p) un petit schéma. Et voilà le schéma corrigé d'une requête DNS. Ces petites explications faites, continuons avec notre record eban.bzh. 1800 IN A 89.234.156.60 . 1800 correspond au TTL (Time to Live) de ce record, c'est le temps en secondes après lequel le serveur DNS résolveur devra réinterroger le serveur DNS autoritaire afin de mettre à jour son cache. Le serveur DNS résolveur gardera donc ce record en cache pendant 1800 secondes puis réinterrogera le serveur DNS autoritaire à la prochaine requête si ce temps est passé. IN A correspond au type du record, ici A qui correspond à un record qui renvoie une adresse IPv4, il existe de nombreux autres types de records, vous trouverez ci-dessous une liste des plus courants. 89.234.156.60 enfin correspond à l'adresse IP qui nous est renvoyée. Type Définition Exemple A Renvoie une Ipv4 eban.bzh. 1800 IN A 89.234.156.60 AAAA Renvoie une Ipv6 eban.bzh. 1800 IN AAAA 2a03:7220:8083:3c00::1 CNAME Renvoie vers un autre record blog.eban.bzh. 1800 IN CNAME veil.eban.bzh. NS Spécifie les NS d'une zone eban.bzh. 1800 IN NS ns1.eban.bzh. MX Indique les serveurs SMTP (mail) à utiliser eban.bzh. 1800 IN MX 10 spool.mail.gandi.net. SOA Contient les informations suivantes, dans l'ordre : Serveur DNS autoritaire principal Email de contact , le @ est remplacé par un point, l'adresse ici est donc ns@eban.bzh Serial \"version\" de la zone Refresh délai en secondes entre demandes d'update des slaves Retry délai en secondes entre demandes d'update lors d'un fail Expire expiration de la zone Minimum TTL TTL pour les records inexistants eban.bzh. 86400 IN SOA ns1.eban.bzh. ns.eban.bzh. 1618240745 10800 3600 604800 10800 Si vous voulez essayer d'interroger les serveurs DNS à la main, dig(1) est un bon outil, il existe aussi la commande nslookup pour les hérétiques personnes sous Windows. Pour les plus curieux, voici un petit bonus :) Nous allons analyser ce qui se passe concrètement sur un réseau local lors d'un requête DNS vers un serveur DNS résolveur. Cette petite analyse est faite sur un système basé sur linux mais est aussi valable pour Windows. J'ai donc capturé le trafic sortant de ma machine avec un outil nommé tcpdump(8) . Et voici ce que l'on obtient 10 : 31 : 13.272734 IP 10.2 . 0.2 . 60081 > 10.0 . 0.1 . 53 : proto UDP A ? eban . bzh . ( 37 ) 10 : 31 : 13.309725 IP 10.0 . 0.1 . 53 > 10.2 . 0.2 . 60081 : proto UDP A 89.234 . 156.60 ( 53 ) On voit donc que l'ordinateur va interroger le serveur DNS (ici sur 10.0.0.1 ) sur le port 53 qui est le port par défaut du protocole DNS pour lui demander un record A pour la zone eban.bzh. . On remarque aussi que ce protocole est basé sur le protocole UDP que nous étudierons sûrement d'ici peu longtemps ;). Le serveur DNS répond ensuite à la demande en renvoyant le type de record (ici A ) et l'adresse IP demandée. Voilà, c'en est finit pour ce premier post de la catégorie Today I Learned, demain nous nous intéresserons au fonctionnement à la fonction d'un registrar ainsi qu'au fonctionnement des serveurs DNS autoritaires sur le principe de slave/master .","tags":"misc","url":"https://ilearned.eu.org/les-bases-du-dns.html","loc":"https://ilearned.eu.org/les-bases-du-dns.html"},{"title":"SolarWinds, l'arbre qui cache la forêt 👾","text":"Avant propos Cet article a pour but de retracer les évènements à propos de la récente attaque dont SolarWinds a été victime, ces actualités étant relativement récentes à l'heure où j'écris cet article (07/02/2021) des mises à jour seront sûrement apportées à ce dernier. Signal d'alarme Le 8 décembre 2020, Kevin Mandia, PDG de la société FireEye poste un communiqué nommé FireEye Shares Details of Recent Cyber Attack, Actions to Protect Community dans lequel il informe que l'entreprise a été victime d'une cyberattaque de la part d'un \"acteur hautement sophistiqué\" et que ce dernier avait accédé à leur réseau interne et volé un grand nombre d'outils de Red Team de la société. Ce communiqué fait aussi part du fait que sa discipline, sa sécurité opérationnelle et ses techniques nous conduisent à penser que [l'acteur malveillant derrière cette attaque] était soutenu par un état Matt Gorham le directeur adjoint de la division cyber du FBI indique dans la foulée Le FBI enquête sur l'incident et les premières constatations montrent un acteur avec un haut niveau de sophistication conforme à un État-nation Ce qui semble donc confirmer les dires de FireEye. Le 08 décembre 2020 à 20h11, dans un article le New York Times suppute que Ce piratage soulève la possibilité que les agences de renseignement russes aient vu un avantage à monter l'attaque alors que l'attention américaine - y compris celle de FireEye - était concentrée sur la sécurisation du système des élections présidentielles. Sans pour autant apporter de preuve tangible. Le 13 décembre 2020, coup de tonnerre, FireEye indique dans ce communiqué que l'attaque qu'ils ont subi a été propagée par le système de mise à jour d'Orion, un logiciel de gestion de réseau édité par SolarWinds, un cheval de Troie nommé Sunburst avait été inséré dans les version 2019.4 HF 5, 2020.2 et 2020.2 HF 1 d'Orion. Microsoft, les départements américains du Commerce, du Trésor, de l'Énergie et plus encore ont déclaré avoir été victimes de cette cyberattaque. Un peu de reverse engineering Ce travail d'analyse est en grande partie basé sur les travaux de Colin Hardy. Ce malware a été conçu pour être le plus discret possible, lors de la première exécution, le code malveillant commence par attendre 12 à 14 jours avant de s'exécuter. Puis, il vérifie si le hostname de la machine contient \"solarwinds\" ou \"test\" , ou s'il correspond à une liste de noms d'hôte qui contient, par exemple, swdev.dmz, swdev.local, on peut donc imaginer que l'attaquant a eu accès au réseau local de SolarWinds et a pu collecter ces noms d'hôte… Tout cela dans le but d'éviter que le malware ne se déclenche sur un émulateur d'un AV et qu'il soit détecté. Le malware va ensuite vérifier si, dans la liste des processus actifs sur la machine, un ou plusieurs correspond à une liste qui contient les noms de processus d'antivirus (f-secure gatekeeper, carbonblack), de Command and Control (csagent, csfalconcontainer) - probablement afin de ne pas infecter une machine qui le serait déjà - de logiciels de virtualisation (vboxservice) et même d'analyse réseau (wireshark, tcpdump). Tout cela dans la but de rester le plus discret possible. Puis, un userID est créé, il est généré à partir du hostname de la machine, du MachineGuid et de l'adresse MAC Le code malveillant fait ensuite appel au domaine avsvmcloud.com , il génère une URL avec la fonction suivante Cette URL est composée du domaine eu-west-1.appsync-api.avsvmcloud.com (la eu-west-1 peut aussi être us-west-2 , us-east-1 ou us-east-2 , le choix est fait aléatoirement) et d'un sous domaine qui est généré par la fonction DecryptShort à partir du UserID généré plus tôt et du hostname de la machine. C'est à partir de ce sous-domaine que la machine communique avec le C2. Je n'irais pas plus loin dans l'analyse de ce malware, la partie communication avec le C2 étant relativement complexe et peu intéressante selon moi. Conclusion Le 10 juin 2021, le spécialiste en cybersécurité Kaspersky publie un article dans lequel il indique que la backdoor de Sunburst a beaucoup de similitude avec une autre nommée Kazuar, une backdoor qui a été attribuée à la Russie. Cette attaque pourrait donc etre appuyée par le FSB. Le 29 janvier 2021, Brandon Wales, dirigeant du CISA a révélé dans le Wall Street Journal que 30 % des victimes de l'attaque ne seraient pas clientes de SolarWinds, cette attaque pourrait donc etre seulement la face visible d'une grande opération de cyberespionnage. Merci beaucoup d'avoir lu cette article, si vous avez des questions / remarques, n'hésitez pas à m'en faire part ici ou par mail à contact@eban.bzh","tags":"misc","url":"https://ilearned.eu.org/solarwinds-larbre-qui-cache-la-foret.html","loc":"https://ilearned.eu.org/solarwinds-larbre-qui-cache-la-foret.html"},{"title":"WannaCry, le virus le plus dévastateur jamais créé 👾","text":"En mai 2017, un virus informatique du nom de WannaCry fait son apparition, il a infecté quelques 300 000 ordinateurs dans plus de 150 pays ! Trois ans plus tard, revenons ensemble sur le ransomware le plus dévastateur jamais créé. La genèse du projet Le 13 août 2016, un groupe de hackers dénommé The Shadow Brokers met en libre téléchargement sur Tumblr, GitHub et Pastebin de nombreux programmes d'espionnage et de piratage informatique de la NSA dont la faille de sécurité EternalBlue, cette dernière permettant une RCE (remote code execution) sur un machine distante à partir d'un partage SMBv1 (plus d'infos ici ). Cette vulnérabilité a été utilisée par le malware WannaCry afin de se propager. Ce virus aujourd'hui attribué a la Corée du Nord et plus particulièrement au groupe Lazarus par de nombreux acteurs tel que le conseiller à la sécurité intérieure des USA Tom Bossert ou le chercheur en cybersécurité Matthieu Suiche interrogé par Envoyé Spécial aurait donc été créé dans un but lucratif. Fonctionnement du Ransomware Comme vu plus haut, WannaCry se propage tout seul (c'est un virus auto-répliquant ou vers) grâce à la faille de sécurité EternalBlue. Une fois executé sur la machine, le logiciel se met à chiffrer tout les fichiers personnels de l'ordinateur avec la méthode de chiffrement AES-128 (Une paire de clés RSA est générée au lancement du programme, la clé privée était utilisée pour chiffrer les fichiers). Après l'infection, une somme équivalente à 300€ (voir 600€ en fonction des cas) en Bitcoin est demandée pour déchiffrer les fichiers. Il n'existe aucune preuve du fait que les personnes derrière WannaCry sont en capacité de déchiffrer les fichiers. En effet, il est impossible pour les pirates de relier une transaction à un ordinateur spécifique. Une fois lancé, le logiciel installe aussi Tor sur la machine et essaie de se connecter aux serveurs C2 ( Command and Control ) suivants: gx7ekbenv2riucmf.onion 57g7spgrzlojinas.onion xxlvbrloxvriy2c5.onion 76jdd2ir2embyv47.onion cwwnhwhlz52maqm7.onion Un Antidote ? Un groupe de trois experts en sécurité informatique français ont créé logiciel nommé Wanakiwi . Cet outil permet de déchiffrer les fichiers qui l'ont été par WannaCry. WannaCry utilise CryptoAPI (les fonctions cryptographiques de Windows) pour générer les clés de chiffrement, cependant ces fonctions inscrivent dans la RAM de l'ordinateur la clé privée en claire, WanaKiwi va donc aller chercher dans la RAM des traces de la clé privée utilisée pour chiffrer les données. Comment se prémunir de ce type d'attaques dans le futur ? On ne le dira jamais assez, mais n'ouvrez jamais de pièces jointes venant d'un destinataire inconnu. Mettez à jour régulièrement votre OS, Microsoft propose une fonction très intéressante dans leur suite de sécurité Windows Defender nommée Dispositif d'accès contrôlé aux dossiers . Cet outil permet de contrôler l'accès aux fichiers systèmes de Windows et aux données personnelles des utilisateurs par des programmes, il fonctionne avec un système de withelist, chaque programme doit donc être autorisé manuellement pour pouvoir modifier ces fichiers (plus d'infos ici ). Merci d'avoir lu cet article, j'espère qu'il vous aura plu. Je suis preneur de vos retours :) Remerciements Merci à xeway, 0xThxmxs, Shcanovishka, Sycorax, look, Ramle et Lancelot de m'avoir aidé pour la relecture. Sources : https://fr.wikipedia.org/wiki/WannaCry https://fr.wikipedia.org/wiki/The_Shadow_Brokers https://docs.microsoft.com/fr-fr/security-updates/SecurityBulletins/2017/ms17-010 https://www.washingtonpost.com/world/national-security/us-set-to-declare-north-korea-carried-out-massive-wannacry-cyber-attack/2017/12/18/509deb1c-e446-11e7-a65d-1ac0fd7f097e_story.html https://yewtu.be/watch?v=Mp3TH5PI6rc https://www.secureworks.com/research/wcry-ransomware-analysis https://fr.wikipedia.org/wiki/Cryptographic_Application_Programming_Interface https://docs.microsoft.com/fr-fr/windows/security/threat-protection/microsoft-defender-atp/evaluate-controlled-folder-access","tags":"Culture Hack","url":"https://ilearned.eu.org/wannacry-le-virus-le-plus-devastateur-jamais-cree.html","loc":"https://ilearned.eu.org/wannacry-le-virus-le-plus-devastateur-jamais-cree.html"},{"title":"Vos mots de passe sont ils vraiment sécurisés 🔐","text":"Aujourd'hui, nous utilisons des mots de passe partout, pour déverrouiller son téléphone, son ordinateur, son compte en banque et bien d'autres. Il parait donc indispensable d'avoir des mots de passe forts pour sécuriser ces comptes. Dans cet article nous allons donc nous pencher sur comment sécuriser ces précieux sésames. 1) Avoir des mots de passe différents Il est très important d'avoir des mots de passe différents sur chaque compte, imaginez un de vos comptes est piraté et votre mot de passe est récupéré, il suffirait donc au pirate de réutiliser ce même mot de passe sur tous vos comptes pour y avoir accès… Etant donné qu'il est impossible de retenir des dizaines de mots de passe différents, les gestionnaires de mots de passe ont été inventés, ils permettent de n'avoir qu'à retenir qu'un mot de passe, celui de votre gestionnaire ! Il existe de nombreux services de gestionnaires de mots de passe, je vous conseille : https://apps.nextcloud.com/apps/passwords (Si vous avez un cloud Nextcloud, Nexcloud Passwords est le meilleur gestionnaire de mots de passe) https://bitwarden.com/ (Très bon gestionnaire de mot de passe entièrement open source) Il ne vous reste plus qu'à installer un de ces services sur tout vos appareils. 2) Utiliser des mots de passe vraiment complexes Le meilleur moyen d'avoir des mots de passe sécurisés est d'utiliser des caractères spéciaux, traditionnellement on recommande d'utiliser des caractères comme @, $ ou *. Il existe cependant une façon plus facile mais méconnue d'avoir un mot de passe complexe facilement, les emojis . Beaucoup de services acceptent les emojis comme mot de passe ! En voici une liste : Twitter ✅ Github ✅ Amazon ✅ Discord ✅ Protonmail ✅ Spotify ✅ On peut aussi, pour sécuriser nos mots de passe, utiliser des caractères d'autres alphabets que l'alphabet latin, du cyrillique, des lettres de l'alphabet arabe ou même des caractères en Japonais, Coréen, en bref tous les charactères de la table Unicode. Pour simplifier cette démarche de création de mot de passe, j'ai fait un petit script Python sur mon Github disponible ici Il est enfin, très important d'activer l'A2F sur tous vos comptes, je recommande l'app Aegis pour mettre en place cette authentification à deux facteurs. Il existe aussi des Clés USB A2F ! Plus sécurisées qu'une app sur mobile… En voici une liste : https://shutuptrackers.com/hardware/authentification.php Remerciements Merci à Erispar pour la relecture. Merci à 0x66 de m'avoir donné l'idée de parler des Clés USB A2F.","tags":"Tutoriel","url":"https://ilearned.eu.org/vos-mots-de-passe-sont-ils-vraiment-securises.html","loc":"https://ilearned.eu.org/vos-mots-de-passe-sont-ils-vraiment-securises.html"},{"title":"Debuter dans l'infosec 👨‍💻","text":"Dans ce nouvel article, nous allons traiter de la fameuse question La sécurité informatique, ca m'intéresse, mais par où commencer ? Par où commencer, la question est vaste mais voici un petit résumé des prérequis nécessaires pour commencer dans l'Infosec : Pour commencer dans le monde de la cybersecurité, il est recommandé d'apprendre un language de scripting tel que le python ( voici un très bon cours venant du site de zeste de savoir , les bases des languages web sont aussi quasi-indispensables ( ici ou là vous pourrez trouver un cours sur le html, le css, le js ainsi que le php) il est aussi important d'apprendre les bases du fonctionnement des protocoles réseaux les plus courants (voici un cours qui peut vous aider à comprendre ces protocoles), pour finir, je recommanderais de passer sous une distribution Linux comme Ubuntu ou Arch pour les plus téméraires et de vous familiariser avec cet OS et au terminal linux. Une fois tout ces prerequis validés, vous pourrez vous entrainer sur Root-Me Spécialisation Après avoir découvert les bases de ce milieu, vous pourrez vous spécialiser dans certains domaines spécifiques Le RE(Reverse Engineering / Rétro Ingénerie) Le Reverse Engineering est le fait d'étudier le fonctionnement d'un programme pour en comprendre le fonctionnement sans avoir le code source de celui-ci. Pour débuter dans ce domaine, il est indispensable de connaitre le language C ainsi que de l'assembleur (de préférence x86_64). Vous pourrez alors vous entraîner sur des crackme, si vous voulez de l'aide ou seulement discuter de ces sujets, je vous invite à rejoindre l'un des serveurs discord listés ci-dessous. Les CTFs Les CTFs consistent en un machine faite pour être piratée , le but est de devenir administrateur (ou root ) de la machine en utilisant plusieurs failles informatiques. Pour vous entrainer à cela, je vous invite à aller sur HackTheBox ainsi que sur Vulnhub . Comme dans le domaine du reverse engineering, si vous avez besoin d'aide pour le CTF n'hésitez pas à rejoindre un serveur discord, parfois les plateformes proposent le leur pour les haxors. Bonus : Ressources Voici une liste non exhaustive de ressources qui pourraient vous aider : https://github.com/wapiflapi/exrs (Exercices de RE) https://root-me.org/ (Challenges toutes catégories) https://www.newbiecontest.org/ (Challenges toutes catégories) https://www.hackthebox.eu/ (Challenges, plus orienté test d'intrusion) https://www.vulnhub.com/ (VM vulnérables) https://www.dailysecurity.fr/ (Blog de Geluchat) https://beta.hackndo.com/ (Blog de pixis) https://www.hacktion.be/ (Blog de Que20) https://inf0sec.fr/ (Blog de Unknow101 orienté test d'intrusion windows) https://sideway.re/ (Blog de @SideWay'CSS ) https://inshallhack.org/ (Blog de l'équipe française de CTF [Inshall'hack] (https://ctftime.org/team/44256)) https://www.google.fr/ (RTFM, la base avant toute question.) http://exploit.education/ (Un bon site pour débuter en pwn) Rainbow (Serveur discord parlant d'infosec mais aussi de programmation.) inf0sec (Serveur discord de [@inf0sec1] (https://twitter.com/inf0sec1) parlant de cybersécurité) ret2school (Serveur discord de @nasm_re et de l'équipe de CTF, ret2school ) Remerciements : Merci à SoEasY de m'avoir aidé pour la définition du RE. Merci à MorpheusH3x pour la liste des ressources.","tags":"misc","url":"https://ilearned.eu.org/debuter-dans-linfosec.html","loc":"https://ilearned.eu.org/debuter-dans-linfosec.html"},{"title":"Getting started in infosec","text":"In this new article, we will deal with the famous question \"I'm interested in computer security, but where to start?\" Where to start, the question is vast but here is a small summary of the prerequisites necessary to start in Infosec : To start in the world of cybersecurity, it is recommended to learn a scripting language such as Python (here is a very good course coming from the site of zeste de savoir (fr) ), the basics of web languages are also almost essential ( here (fr) or there (fr) you can find a course on html, css, js and php ) it is also important to learn the basics of how the most common network protocols work ( here (fr) is a course that can help you understand these protocols). Finally, I would recommend to switch to a Linux distribution like Ubuntu or Arch for the more adventurous and to familiarize yourself with this OS and the Linux terminal. Once all these prerequisites are validated, you can train on Root-Me. Specialization : After having discovered the basics of this field, you will be able to specialize in certain specific areas. The RE (Reverse Engineering) : Reverse Engineering is the fact of studying the functioning of a program to understand its operation without having the source code of it. To start in this field, it is essential to know the C language ressource (fr) and assembler (preferably x86_64) ressource (fr) . You will then be able to train on crackme, if you want help or just discuss these topics, I invite you to join one of the discord servers listed below. CTFs : The CTFs consist in a machine made to be hacked , the goal is to become administrator (or root ) of the machine by using several computer flaws. To practice this, I invite you to go on HackTheBox and on Vulnhub . As in the field of reverse engineering, if you need help for CTF do not hesitate to join a discord server, sometimes platforms propose their own for haxors. Bonus : Resources Here is a non-exhaustive list of resources that might help you: https://github.com/wapiflapi/exrs (RE exercises) https://root-me.org/ (Challenges: all categories) https://www.newbiecontest.org/ (Challenges: all categories) https://www.hackthebox.eu/ (Rooms penetration test oriented) https://www.vulnhub.com/ (Vulnerable VMs, like hackthebox but locally) https://www.dailysecurity.fr/ (Geluchat's blog) https://beta.hackndo.com/ (pixis's blog) https://www.hacktion.be/ (Que20's blog) https://inf0sec.fr/ (Unknow101's blog about windows penetration testing) https://sideway.re/ (Blog of @SideWay'CSS ) https://inshallhack.org/ (Blog of the french CTF team Inshall'hack ) https://www.google.fr/ (RTFM, the base before any question) http://exploit.education/ (A site that will teach you the basics in pwn) https://cryptopals.com/ (A site that will teach you the basics in crypto) Rainbow (Discord server talking about infosec but also programming) inf0sec (Discord server from @inf0sec1 talking about cybersecurity) ret2school (Discord server from @nasm_re and the ret2school team ) Acknowledgements : Thanks to SoEasY for helping me with the RE definition. Thanks to MorpheusH3x for the list of resources. Translated by MorpheusH3x .","tags":"i18n","url":"https://ilearned.eu.org/getting-started-in-infosec.html","loc":"https://ilearned.eu.org/getting-started-in-infosec.html"},{"title":"AdGuard Home, La sécurité et la vie privée dans votre maison 🛡️","text":"Dans ce nouvel article, nous allons traiter du logiciel open-source AdGuard Home qui est un bloqueur de publicités et de trackers qui intègre des fonctions supplémentaires tel que le DOH qui permet de chiffrer les requêtes DNS de votre réseau Wi-Fi ! A quoi bon ? Il est vrai que l'on pourrait se demander à quoi pourrait servir un tel outil. Laissez moi vous expliquer : quand vous possédez un appareil connecté à Internet (téléphone, tablette, ordinateur, etc.), des trackers enregistrent votre activité afin de revendre ces données à des annonceurs leur permettant ainsi de faire de la publicité ciblée. Ces données peuvent révéler beaucoup sur vous, tel que votre localisation, votre situation familiale, votre état de santé, etc. C'est pourquoi il est très important de se protéger de ces trackers. Prérequis Pour ce tutoriel, vous aurez besoin : • D'un Raspberry Pi disposant d'un module WiFi • D'un câble RJ45 (Ethernet) Et c'est tout ! Tutoriel Dans ce tutoriel nous allons donc voir l'installation de RaspAP qui permet de faire un point d'accès wifi à partir d'un cable Ethernet branché au Raspberry Pi puis nous verrons l'installation de AdGuard Home ainsi que l'activation de la compatibilité avec le DOH (DNS over HTTPS qui permet de chiffrer vos requetes DNS). 1) Installation de RaspAP Pour débuter l'installation de RaspAP, effectuez la commande suivante sur votre Raspberry Pi sudo apt update && sudo apt upgrade -y && wget -q https://git.io/voEUQ -O /tmp/raspap && bash /tmp/raspap L'installateur va s'ouvrir, il vous demande d'abord dans quel répertoire vous souhaitez installer RaspAP à moins que vous ne souhaitez le changer, laissez le répertoire de base, répondre oui à tout (y) sauf au moment où il vous sera proposé d'installer le bloqueur de publicités, nous n'utiliserons pas celui intégré à RaspAP car il est moins performant que AdGuard Home. À la dernière étape, l'installateur vous demandera si vous souhaitez redémarrer le Raspberry Pi, répondez oui. Une fois votre Raspberry Pi redémarré, vous pourrez vous rendre sur l'interface web de votre Raspberry Pi, à noter que les identifiants de connexi sont \"admin\"/\"secret\". Pour y accéder, tapez juste l'adresse IP locale de votre Raspberry Pi dans votre navigateur, et depuis cette interface, vous pourrez change le SSID (nom du réseau), les informations de connexion, etc. Nous avons donc finit d'installer RaspAP, aucune configuration de ce dernier n'est nécessaire pour l'instant. 2) Installation de AdGuard Home Pour commencer l'installation de AdGuard Home, entrez la commande suivante sur votre Raspberry Pi wget https://static.adguard.com/adguardhome/release/AdGuardHome_linux_arm.tar.gz && tar -xf AdGuardHome_linux_arm.tar.gz && cd AdGuardHome && sudo ./AdGuardHome -s install Rendez-vous ensuite sur l'interface d'installation qui se situe à l'adresse. http://IPLOCALEDEMONRASPBERRYPI:3000 Après avoir cliqué sur \"C'est parti\", dans la partie \"Interface web administrateur\", laissez \"Toutes les interfaces\" et changez le port pour, disons par exemple, 1234. Dans la partie \"Serveur DNS\", choisissez 127.0.0.1 à la place de \"Toutes les interfaces\" et mettez 5300 dans la case port. Cliquez sur le bouton Suivant puis renseignez vos informations de connexion à l'interface d'administration Une fois cela fait, cliquez sur Suivant puis \"ouvrir le Tableau de bord\", entrez vos identifiants de connexions puis allez dans la section Filtres puis Listes de blocage DNS. Cochez toutes les cases et ajoutez la liste : \"https://raw.githubusercontent.com/hl2guide/Filterlist-for-AdGuard/master/filter_blocklist.txt\" en cliquant sur la bouton Ajouter liste de blocage. Pour finaliser l'installation, rendez-vous sur l'interface d'administration de RaspAP, les identifiants de connexion sont par défaut \"admin\"/\"secret\". Puis dans la section DHCP server, cliquez sur Advanced, puis cochez la case \" Only ever query DNS servers configured below\". Renseignez ensuite \"127.0.0.1#5300\" dans la case Add upstream DNS server, puis cliquez sur le bouton + Pour finir, redémarrez le Point D'accès en cliquant sur le bouton Restart hotspot dans la section \"Hotspot\". Et voilà ! L'installation de RaspAP et de AdGuard Home est terminée ! 3) Bonus : Mise en place du DOH ainsi que d'un VPN Pour mettre en place le DOH, allez sur l'interface d'administration de AdGuard Home puis dans paramètres, paramètres DNS, renseignez le DOH de votre choix, dans mon cas, j'ai choisi https://doh.powerdns.org/ Vos requêtes DNS sont maintenant chiffrées ! Conclusion Et voilà ! C'est terminé, vous pouvez maintenant naviguer sur internet sans publicités ni trackeurs ! Veillez à bien modifier le mot de passe ainsi que le SSID de votre réseau wifi ! Vous n'avez plus qu'à connecter tout les appareils de votre maison au nouveau réseau Wi-Fi et ils seront protégés à leur tour ? Si vous avez des questions, n'hésitez pas à me contacter sur twitter @eban_non ou par mail ebandev@protonmail.com. Merci à Azgar de m'avoir aidé pour la relecture","tags":"misc","url":"https://ilearned.eu.org/adguard-home-la-securite-et-la-vie-privee-dans-votre-maison.html","loc":"https://ilearned.eu.org/adguard-home-la-securite-et-la-vie-privee-dans-votre-maison.html"},{"title":"Windows security model","text":"Introduction \"Access denied\". If there is a frustrating error, it is surely this one. On Windows we are often confronted with it, especially from an attacking perspective. However, few people understand why this error (or others) interferes with their comfortable use of their operating system. In this article, I will try to give you an overview of the security model used by Windows, mainly the notions of access privilege and access control. Generally speaking, when I talk about Windows objects, I am talking about users, machines, files, or even processes. Security environment To understand what follows, it is necessary to understand what a security context is in our friend Windows. The latter designates a set of attributes or security rules currently in force, as defined by Microsoft. A security context will be translated by a particular data structure defined by the SSPI (\"Security Support Provider Interface\"), a Windows API written in order to interact with the security context, it is used, for example, for authentication. In other words, the security context defines the basic elements of the security system of our favorite OS (if it doesn't, pretend it does). SecurableObject An object is said to be \"securable\" if it has the ability to have a security descriptor. In general, a lot of objects in Windows are SecurableObjects . Processes, registry keys, files/directories, Active Directory objects and many others. They form the core of the interactions between us and the operating system. I mentioned security descriptors, these are simply lists of several characteristics. They contain the SID (\"Security Identifier\", which is a unique identifier) of the owner of the object, the SID of the owner group, and ACLs for \"Access Control Lists\". Security descriptors are usually in the SDDL (\"Security Descriptor Definition Language\") format, which, although not very nice, is actually very practical because it is easy to use (not to understand). Access tokens When a Windows user logs into his local account (or Active Directory) several pieces of information will be stored in the memory. Obviously, it will contain the password digest (except for very unlikely configurations or a relatively old system, in which case it will be the password in clear), his SID , the SID of his group, access privileges (we'll come back to this later) and many other information. All this is gathered in what is called an access token. This is then kept in a special process called LSASS.exe for \"Local Security Autority SubSystem Service\". It is therefore vital and very sensitive. When we interact with the system in any way, a copy of our access token is used. In the case of a file, the information that the access token contains will then be compared with the information in the DACL (which is a list containing the accesses, more on that later) guaranteeing or not an access of a certain value. It can be intended for writing, reading or even for execution. A more interesting case is that of starting a program. Indeed, the latter is launched as a particular user, so it must not bypass this famous access system. This is why processes are considered SecurableObjects , and in this situation, a copy of our token access is also given and when the program interacts with the system, it will do so according to the rights and identity of the connected user. The function CreateProcessA() is a function of the Windows API kernel32.dll which allows to create a new process. Access privileges As mentioned earlier, the access token contains a number of privileges within it. These are assigned to each connection, according to the security rules. More precisely, access privileges are given according to the group to which one belongs, to which one assigns default rights through local GPOs (in gpedit.msc , Computer Configuration , Security Settings , Local Policies , User Rights Assignment ). The list of these privileges is not presented as a classical enumeration, but here is a PowerShell implementation to get a good idea of all these privileges (from PSReflect-Functions ). $SecurityEntity = psenum $ENUM SecurityEntity UInt32 @{ SeCreateTokenPrivilege = 1 SeAssignPrimaryTokenPrivilege = 2 SeLockMemoryPrivilege = 3 SeIncreaseQuotaPrivilege = 4 SeUnsolicitedInputPrivilege = 5 SeMachineAccountPrivilege = 6 SeTcbPrivilege = 7 SeSecurityPrivilege = 8 SeTakeOwnershipPrivilege = 9 SeLoadDriverPrivilege = 10 SeSystemProfilePrivilege = 11 SeSystemtimePrivilege = 12 SeProfileSingleProcessPrivilege = 13 SeIncreaseBasePriorityPrivilege = 14 SeCreatePagefilePrivilege = 15 SeCreatePermanentPrivilege = 16 SeBackupPrivilege = 17 SeRestorePrivilege = 18 SeShutdownPrivilege = 19 SeDebugPrivilege = 20 SeAuditPrivilege = 21 SeSystemEnvironmentPrivilege = 22 SeChangeNotifyPrivilege = 23 SeRemoteShutdownPrivilege = 24 SeUndockPrivilege = 25 SeSyncAgentPrivilege = 26 SeEnableDelegationPrivilege = 27 SeManageVolumePrivilege = 28 SeImpersonatePrivilege = 29 SeCreateGlobalPrivilege = 30 SeTrustedCredManAccessPrivilege = 31 SeRelabelPrivilege = 32 SeIncreaseWorkingSetPrivilege = 33 SeTimeZonePrivilege = 34 SeCreateSymbolicLinkPrivilege = 35 } And yes, 35 privileges is a lot. But what are they for? They allow to perform some system tasks. They should not be confused with ACE (\"Access Control Entry\", which is a right assigned in a DACL ), because the latter defines access to a SecurableObject . For example, the SeBackupPrivilege right is given to any member of the Backup Operators group and allows you to read the contents of a file regardless of its ACLs (unless you are explicitly prohibited from doing so). The SeRestorePrivilege right allows identically to write a file. The SeDebugPrivilege right (reserved to Administrators), allows to access and manipulate the memory of another program, a program we have not launched. It is typically this right that Mimikatz asks for to access the famous password digests kept by LSASS.exe . *You can find a complete list of the rights given by which privilege in the [official Microsoft documentation] (https://docs.microsoft.com/en-us/windows/win32/secauthz/privilege-constants). These privileges are naturally very powerful and you should not neglect their security, who has what. Now, how can I clearly see which privileges I have? The simplest command for this is whoami /all . whoami.exe opens the token of its own process, and as we said earlier, it contains all the information the system needs to complete its tasks, including access to SecurableObjects . Thus, we can see our privileges ( whoami /priv ), our groups ( whoami /groups ), our SID ( whoami /user ) and many others. A small example, once logged in, I launch a PowerShell command prompt and type whoami /priv . By bad luck, the right seems to be disabled. Windows PowerShell Copyright (C) Microsoft Corporation. Tous droits réservés. Testez le nouveau système multiplateforme PowerShell https://aka.ms/pscore6 PS D:\\> whoami /priv Informations de privilèges ---------------------- Nom de privilège Description État ============================= ============================================ ========= SeShutdownPrivilege Arrêter le système Désactivé SeChangeNotifyPrivilege Contourner la vérification de parcours Activé SeUndockPrivilege Retirer l'ordinateur de la station d'accueil Désactivé SeIncreaseWorkingSetPrivilege Augmenter une plage de travail de processus Désactivé SeTimeZonePrivilege Changer le fuseau horaire Désactivé PS D:\\> So to shut down my computer I have to activate this right. Thanks to some hidden magic I can activate it (in reality I'm just using an implementation of the RtlAdjustPrivilege function of NTDLL.dll , which allows to adjust the privileges for our process, in PowerShell) and we can see that now I can turn off my computer. PS D:\\tools\\PowerShellScript\\PSReflect-Functions> RtlAdjustPrivilege -Privilege SeShutdownPrivilege -Verbose COMMENTAIRES : [RtlAdjustPrivilege] Attempting to enable 'SeShutdownPrivilege' for the current process COMMENTAIRES : [RtlAdjustPrivilege] enable for 'SeShutdownPrivilege' successful PS D:\\tools\\PowerShellScript\\PSReflect-Functions> whoami /priv Informations de privilèges ---------------------- Nom de privilège Description État ============================= ============================================ ========= SeShutdownPrivilege Arrêter le système Activé SeChangeNotifyPrivilege Contourner la vérification de parcours Activé SeUndockPrivilege Retirer l'ordinateur de la station d'accueil Désactivé SeIncreaseWorkingSetPrivilege Augmenter une plage de travail de processus Désactivé SeTimeZonePrivilege Changer le fuseau horaire Désactivé PS D:\\tools\\PowerShellScript\\PSReflect-Functions> Except that after a game of \"CS:GO\" with a Russian team the \"ragequit\" would be somewhat boring. That's why it is possible to activate or deactivate privileges. Be careful, these must be contained in our initial access token , otherwise it would be much too easy. When we use a program like \"shutdown.exe\" it will use some functions of the WinAPI ( AdjustTokenPrivileges of advapi32.dll for the curious) to change its privileges, and thus be able to say goodbye to our game won in advance. Access lists There are two types. The first is the SACL for \"System Access Control List\" which is probably the simplest. Indeed, it allows to establish a certain number of rules concerning the access audit to the object carrying this list. You can then define in this list which event, for which user, should be recorded in the event logs. The other type is called DACL for \"Discretionary Access Control List\". The DACL contains a number of ACE (\"Access Control Entry\") which specify the type of right granted to an object. Their structure is quite elementary. In addition, an ACE contains a header determining its type, i.e. access allowed or denied, and other information. The header, in turn, contains the right guaranteed or not. This right is called an access mask. We list what we call the standard rights which are elementary: DELETE is the right to delete the object, granted it wasn't a very complex one. READ_CONTROL is the right to read the SACL/DACL . WRITE_DAC is the right to modify the entries in the DACL , i.e. add ACEs . WRITE_OWNER is the right to modify the owner of an object, the interest being that the owner implicitly has all the desired rights. These standard rights are then used to build what are called generic rights: GENERIC_READ allows, as its name indicates, to read the attributes and properties of an object. If it is a file for example, this right allows to read the content of the file. Its equivalent under linux is the \"r\" flag. GENERIC_WRITE allows the modification of the object's properties and attributes. To continue in the previous example, this right allows the modification of its content. Its linux equivalent is the \"w\" flag. GENERIC_EXECUTE allows to read the permissions of an object. In fact if it is a program, it allows to launch it. Its linux equivalent would be the \"x\" flag. GENERIC_ALL is the combination of these rights. Be careful though, it is significantly stronger, in very rare cases. It may turn out that the combination GENERIC_READ/WRITE/EXECUTE is not equivalent to GENERIC_ALL , so it has no equivalent in the penguin system. There are still a lot of them but the objective is not to be exhaustive. To see these accesses, you have to use the security tab of an object's properties. We can also use our favorite shell aka PowerShell (here you have no excuse because PowerShell is great and opensource). There is a special command for this: Get-Acl . It takes as argument the path to our object, -Path and that's about it for simple use. The result is a \"table\" which is quite uncomfortable. To get rid of this display problem, we use a | pipe to the Format-List command (or its alias fl ). We can then see the owner of the file in our case, the accesses granted and the security descriptor in SDDL format. PS D:\\tools\\PowerShellScript\\PSReflect-Functions> Get-Acl .\\ | fl Path : Microsoft.PowerShell.Core\\FileSystem::D:\\tools\\PowerShellScript\\PSReflect-Functions Owner : DESKTOP-8Q2CUHH\\Lancelot Group : DESKTOP-8Q2CUHH\\Aucun Access : BUILTIN\\Administrateurs Allow FullControl BUILTIN\\Administrateurs Allow 268435456 AUTORITE NT\\Système Allow FullControl AUTORITE NT\\Système Allow 268435456 AUTORITE NT\\Utilisateurs authentifiés Allow Modify, Synchronize AUTORITE NT\\Utilisateurs authentifiés Allow -536805376 BUILTIN\\Utilisateurs Allow ReadAndExecute, Synchronize BUILTIN\\Utilisateurs Allow -1610612736 Audit : Sddl : O:S-1-5-21-1739485902-3336647338-3362325240-1001G:S-1-5-21-1739485902-3336647338-3362325240-513D:(A;ID;FA;;;BA)(A;OICIIOID;GA;;;BA)(A;ID;FA;;;SY)(A;OICIIOID;GA;;;SY)(A;ID;0x1301bf;;;AU)(A;OICIIOID;SD GXGWGR;;;AU)(A;ID;0x1200a9;;;BU)(A;OICIIOID;GXGR;;;BU) PS D:\\tools\\PowerShellScript\\PSReflect-Functions> If you want more details, I invite you to read my article about ACL abuse in ActiveDirectory Let's sum up When a user logs in to his session, information will be kept in memory in an access token . When he wants to start a program, a copy of his token is given. If he interacts with the system, he will have to use his privileges to perform certain operations. If it is not necessary to use them all the time, when we want to access an object (file, process …) our access token serves as an identity card which will be compared with the contents of the DACL of the security descriptor of the object the program/user wants to access. Depending on the different entries in the access list, it will be denied or allowed a certain access. I hope you now have a better understanding of how the Microsoft OS manages permissions. If you liked this article, I invite you to read my articles on access privileges and on the abuse of ACLs in Active Directory (and yes, even if useful for defenders, they are also useful for attackers). Translated by MorpheusH3x","tags":"i18n","url":"https://ilearned.eu.org/secu_windows-en.html","loc":"https://ilearned.eu.org/secu_windows-en.html"}]};